<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>XLMaverick - garabatear of yang</title>
    <link>https://xlmaverick.me/</link>
    <description>Recent content on XLMaverick - garabatear of yang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 20 Aug 2018 21:38:52 +0800</lastBuildDate>
    
        <atom:link href="https://xlmaverick.me/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>关于</title>
      <link>https://xlmaverick.me/about/</link>
      <pubDate>Mon, 20 Aug 2018 21:38:52 +0800</pubDate>
      
      <guid>https://xlmaverick.me/about/</guid>
      
        <description>

&lt;h3 id=&#34;我&#34;&gt;我&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Email：　yangxl0319@163.com&lt;/li&gt;
&lt;li&gt;Education： 上海交通大学(硕士) 　　国防科学技术大学（本科）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;本站架构&#34;&gt;本站架构&lt;/h3&gt;

&lt;p&gt;本站目前采用&lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;作为后台系统，并且使用&lt;a href=&#34;https://www.netlify.com/&#34;&gt;Netlify&lt;/a&gt;进行部署。&lt;/p&gt;

&lt;p&gt;博客的主题模板是从Hugo官方网站上面&lt;a href=&#34;https://github.com/olOwOlo/hugo-theme-even&#34;&gt;下载&lt;/a&gt;的，在主页的搭建过程中，参考了同实验室&lt;a href=&#34;https://www.drifter.fun/&#34;&gt;朱一帆&lt;/a&gt;、&lt;a href=&#34;http://www.aintk.xyz/&#34;&gt;王兆圣&lt;/a&gt;的博客，同时友情链接里面相关的链接。&lt;/p&gt;

&lt;h3 id=&#34;常见问题&#34;&gt;常见问题&lt;/h3&gt;

&lt;p&gt;本列表特整理重复度很高的问题，供新来者参考。&lt;/p&gt;

&lt;p&gt;1.请问如何订阅这个博客？&lt;/p&gt;

&lt;p&gt;回答： &lt;a href=&#34;https://xlmaverick.me/post/2018/07/07/rss添加/&#34;&gt;可参看这篇博客&lt;/a&gt;，需要利用RSS阅读器。&lt;/p&gt;

&lt;p&gt;2.评论显示异常以及不能正常评论。&lt;/p&gt;

&lt;p&gt;回答： 注意本站采用的评论系统是 Disqus，在国内需要翻墙才能使用。&lt;/p&gt;

&lt;h3 id=&#34;友情链接&#34;&gt;友情链接　　　　　　　　　　　　&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.aintk.xyz/&#34;&gt;&lt;strong&gt;隔壁老王&lt;/strong&gt;&lt;/a&gt; 　　　&lt;a href=&#34;https://www.drifter.fun/&#34;&gt;&lt;strong&gt;喜提宝马的朱总&lt;/strong&gt;&lt;/a&gt; 　　　&lt;a href=&#34;https://www.bloodbaby.tech/&#34;&gt;&lt;strong&gt;十亩之间&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://yihui.name/&#34;&gt;&lt;strong&gt;谢益辉的独立博客&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>视觉里程计2-LK</title>
      <link>https://xlmaverick.me/post/%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A12-lk/</link>
      <pubDate>Thu, 16 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://xlmaverick.me/post/%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A12-lk/</guid>
      
        <description>

&lt;h1 id=&#34;视觉里程计2&#34;&gt;视觉里程计2&lt;/h1&gt;

&lt;h2 id=&#34;习题一-lk光流法&#34;&gt;习题一：LK光流法&lt;/h2&gt;

&lt;h3 id=&#34;1-1-光流文献综述&#34;&gt;1.1 光流文献综述&lt;/h3&gt;

&lt;p&gt;我们课上演示了&lt;code&gt;Lucas-Kanade&lt;/code&gt;稀疏光流，用&lt;code&gt;OpenCV&lt;/code&gt;函数实现了光流法追踪特征点。实际上，光流法有很长时间的研究历史，直到现在人们还在尝试用&lt;code&gt;Deep learning&lt;/code&gt;等方法对光流进行改进。本题将指导你完成基于&lt;code&gt;Gauss-Newton&lt;/code&gt;的金字塔光流法。首先，请阅读文献，回答下列问题。
问题:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;按此文的分类,光流法可分为哪几类?&lt;/li&gt;
&lt;li&gt;在&lt;code&gt;compositional&lt;/code&gt;中，为什么有时候需要做原始图像的&lt;code&gt;wrap&lt;/code&gt;？该&lt;code&gt;wrap&lt;/code&gt;有何物理意义?&lt;/li&gt;
&lt;li&gt;&lt;code&gt;forward&lt;/code&gt;和&lt;code&gt;inverse&lt;/code&gt;有何差别?&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;答案&#34;&gt;答案：&lt;/h4&gt;

&lt;p&gt;1.围绕Image Alignment，文章总共介绍了四种方法，分别是&lt;code&gt;FAIA（Forward Additional Image Alignment）&lt;/code&gt;，&lt;code&gt;FCIA（Forward Composition Image Alignment）&lt;/code&gt;，&lt;code&gt;ICIA(Inverse Compositional Image Alignment&lt;/code&gt;)和&lt;code&gt;IAIA（Inverse Additional Image Alignment）&lt;/code&gt;。其中LK对应上述四种中的&lt;code&gt;FAIA&lt;/code&gt;，&lt;code&gt;ICIA&lt;/code&gt;使用于直接法SVO中块匹配方法。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;增量方式\更新方式&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;forward&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;inverse&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;additive&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;FAIA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;IAIA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;compositional&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;FCIA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;ICIA&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;2.首先，我们区分一下&lt;code&gt;compositional&lt;/code&gt;和&lt;code&gt;additive&lt;/code&gt;两种方法，其中：如果迭代的结果是在原始的值（6个运动参数）上增加一个微小量，那么这种方法成为&lt;code&gt;additive&lt;/code&gt;；如果在放射矩阵上乘以一个矩阵（增量运动参数形成的增量放射矩阵），这种方法称为&lt;code&gt;compositional&lt;/code&gt;。这两种方法理论上是等效的，计算量也差不多。&lt;br /&gt;
针对&lt;code&gt;compositional&lt;/code&gt;的两种计算方式&lt;code&gt;FCIA&lt;/code&gt;，&lt;code&gt;ICIA&lt;/code&gt;，都需要在当前位姿估计之前引入增量式&lt;code&gt;warp&lt;/code&gt;以建立半群约束要求。&lt;br /&gt;
FCIA：&lt;code&gt;warp&lt;/code&gt;集合包含&lt;code&gt;identity warp&lt;/code&gt;，&lt;code&gt;warp&lt;/code&gt;集合包含在&lt;code&gt;compositional&lt;/code&gt;操作上是闭的（&lt;code&gt;semi-group&lt;/code&gt;），其中包含&lt;code&gt;Homograph，3D rotation&lt;/code&gt;等。&lt;br /&gt;
ICIA：&lt;code&gt;semi-group&lt;/code&gt;，另外要求增量&lt;code&gt;warp&lt;/code&gt;可逆，其中包括&lt;code&gt;Homograph，3D rotation&lt;/code&gt;等，但是不包括&lt;code&gt;piece wise affine&lt;/code&gt;。
&lt;code&gt;warp&lt;/code&gt;的物理意义：对图像做微小的平移或者仿射变换。&lt;br /&gt;
3.前向（&lt;code&gt;forward&lt;/code&gt;）和后向（&lt;code&gt;inverse&lt;/code&gt;）的对比：&lt;br /&gt;
前向方法对于输入图像进行参数化（包括放射变换以及放射增量）。后向方法则是同时参数化输入图像和模板图像，其中输入图像参数化仿射变换，模板图像参数化放射增量。因此后向方法的计算量显著降低。由于图像灰度值和运动参数非线性化，整个优化过程为非线性的。&lt;br /&gt;
参数化过程主要计算：图像的梯度，位置对运动参数导数，运动参数增量。前向方法中&lt;code&gt;Hessian&lt;/code&gt;是运动参数的函数，提高效率的主要思想是交换模板图像和输入图像的角色；后向方法中，迭代中的&lt;code&gt;Hessian&lt;/code&gt;是固定的。&lt;br /&gt;
前向方法和后向方法在目标函数上不太一样，一个是把运动向量$p$都是跟着$I$（被匹配的图像），但是前向方法中的迭代的微小的量$Δp$使用I计算，后向方法中的$Δp$使用$T$计算，这样计算量变小。&lt;/p&gt;

&lt;h4 id=&#34;题记&#34;&gt;题记&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;两个前向方法的计算复杂度相似，后向方法几乎相等。后向方法的速度远远比前向方法要快；&lt;/li&gt;
&lt;li&gt;前向&lt;code&gt;additive&lt;/code&gt;可以用于任何变形&lt;code&gt;warp&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;反向&lt;code&gt;compositional&lt;/code&gt;只能用于&lt;code&gt;wraps that form groups&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;反向&lt;code&gt;additive&lt;/code&gt;可以用于&lt;code&gt;simple 2D linear warps such as translations and affine warps&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;如果不考虑效率的话，可以使用两种前向方法。前向&lt;code&gt;compositional&lt;/code&gt;的方法中&lt;code&gt;Jacobian&lt;/code&gt;是常量，因此具有一定的优势；&lt;/li&gt;
&lt;li&gt;如果考虑效率的话，那么后向&lt;code&gt;compositional&lt;/code&gt;方法是首选，推导简单，很容易确定；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Jacobian&lt;/code&gt;矩阵和残差计算的方式有关，由于&lt;code&gt;compositional&lt;/code&gt;计算误差的方式会使得雅克比矩阵为常数，通常采用&lt;code&gt;compositional&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;最后的最后，推荐一篇博客，对LK光流的解释以及对相应公式的推导均写的较为详细 &lt;a href=&#34;https://www.twblogs.net/a/5b8190582b71772165ad3c9b&#34;&gt;https://www.twblogs.net/a/5b8190582b71772165ad3c9b&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://blog.csdn.net/wendox/article/details/52505971&#34;&gt;https://blog.csdn.net/wendox/article/details/52505971&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-2-forward-addtive-gauss-newton-光流的实现&#34;&gt;1.2 &lt;code&gt;forward-addtive Gauss-Newton&lt;/code&gt;光流的实现&lt;/h3&gt;

&lt;p&gt;接下来我们来实现最简单的光流，即上文所说的&lt;code&gt;forward-addtive&lt;/code&gt;。我们先考虑单层图像的&lt;code&gt;LK&lt;/code&gt;光流，然后再推广至金字塔图像。按照教材的习惯，我们把光流法建模成一个非线性优化问题，再使用&lt;code&gt;Gauss-Newton&lt;/code&gt;法迭代求解。设有图像&lt;code&gt;1.png&lt;/code&gt;，&lt;code&gt;2.png&lt;/code&gt;，我们在&lt;code&gt;1.png&lt;/code&gt;中提取了&lt;code&gt;GFTT&lt;/code&gt;角点，然后希望在&lt;code&gt;2.png&lt;/code&gt;中追踪这些关键点。设两个图分别为$I_1$，$I_2$，第一张图中提取的点集为$P = {p_i}$，其中$p_i = [x_i,y_i]^T$为像素坐标值。考虑第i个点，我们希望计算$∆x_i, ∆y_i$，满足:&lt;/p&gt;

&lt;p&gt;
$$
\min _{\Delta x_{i}, \Delta y_{i}} \sum_{W}\left\|I_{1}\left(x_{i}, y_{i}\right)-I_{2}\left(x_{i}+\Delta x_{i}, y_{i}+\Delta y_{i}\right)\right\|_{2}^{2}
$$
&lt;/p&gt;

&lt;p&gt;即最小化二者灰度差的平方，其中$ \sum_{W}$表示我们在某个窗口（&lt;code&gt;Window&lt;/code&gt;）中求和（而不是单个像素，因为问题有两个未知量,单个像素只有一个约束,是欠定的）。实践中，取此&lt;code&gt;window&lt;/code&gt;为$8×8$大小的小块,即从$x_i − 4$取到$x_i + 3$，&lt;code&gt;y&lt;/code&gt;坐标亦然。显然,这是一个&lt;code&gt;forward-addtive&lt;/code&gt;的光流，而上述最小二乘问题可以用&lt;code&gt;Gauss-Newton&lt;/code&gt;迭代求解。请回答下列问题，并根据你的回答，实现&lt;code&gt;codeoptical_flow.cpp&lt;/code&gt;文件中的&lt;code&gt;OpticalFlowSingleLevel&lt;/code&gt;函数。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;从最小二乘角度来看，每个像素的误差怎么定义？&lt;/li&gt;
&lt;li&gt;误差相对于自变量的导数如何定义？&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;下面是有关实现过程中的一些提示:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;同上一次作业，你仍然需要去除那些提在图像边界附近的点，不然你的图像块可能越过边界。&lt;/li&gt;
&lt;li&gt;该函数称为单层的光流，下面我们要基于这个函数来实现多层的光流。在主函数中，我们对两张图像分别测试单层光流、多层光流，并与&lt;code&gt;OpenCV&lt;/code&gt;结果进行对比。作为验证，正向单层光流结果应该如图1所示，它结果不是很好，但大部分还是对的。&lt;/li&gt;
&lt;li&gt;在光流中，关键点的坐标值通常是浮点数，但图像数据都是以整数作为下标的。之前我们直接取了浮点数的整数部分，即把小数部分归零。但是在光流中，通常的优化值都在几个像素内变化，所以我们还用浮点数的像素插值。函数&lt;code&gt;GetPixelValue&lt;/code&gt;为你提供了一个双线性插值方法(这也是常用的图像插值法之一)，你可以用它来获得浮点的像素值。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;答案-1&#34;&gt;答案：&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;从最小二乘的角度，每个像素的误差为：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;$$
g(p) = I(W(x;p+∆p)) - T(x)
$$&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;误差相对于自变量的导数为：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;$$
\frac{\partial g}{\partial p}=\nabla \mathrm{I} \frac{\partial W}{\partial p}=\left[\frac{\partial I}{\partial x}, \frac{\partial I}{\partial y}\right]
$$&lt;/p&gt;

&lt;p&gt;最终结果为：(右边为opencv结果)&lt;/p&gt;

&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/视觉里程计-LK/single_f.png&#34; width=&#39;350&#39;&gt; &lt;img src=&#34;../images/视觉里程计-LK/opencv_op.png&#34;  width=&#34;350&#34;&gt;
&lt;/div&gt;

&lt;h4 id=&#34;题记-1&#34;&gt;题记&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;对于LK光流的总结和公式推导:&lt;br /&gt;
&lt;a href=&#34;https://blog.csdn.net/sgfmby1994/article/details/68489944。&#34;&gt;https://blog.csdn.net/sgfmby1994/article/details/68489944。&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-3-反向法&#34;&gt;1.3 反向法&lt;/h3&gt;

&lt;p&gt;在你实现了上述算法之后，就会发现，在迭代开始时，&lt;code&gt;Gauss-Newton&lt;/code&gt;的计算依赖于$I_2$在$(x_i,y_i)$处的梯度信息。然而，角点提取算法仅保证了$I_1(x_i,y_i)$处是角点(可以认为角度点存在明显梯度)，但对于$I_2$，我们并没有办法假设$I_2$在$x_i,y_i$处亦有梯度，从而&lt;code&gt;Gauss-Newton&lt;/code&gt;并不一定成立。反向的光流法(inverse)则做了一个巧妙的技巧，即用$I_1(x_i,y_i)$处的梯度，替换掉原本要计算的$I_2 (x_i + ∆x_i,y_i+∆y_i)$的梯度。这样做的好处有:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$I_1(x_i,y_i)$是角点，梯度总有意义；&lt;/li&gt;
&lt;li&gt;$I_1(x_i,y_i)$处的梯度不随迭代改变，所以只需计算一次，就可以在后续的迭代中一直使用，节省了大量计算时间。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们为&lt;code&gt;OpticalFlowSingleLevel&lt;/code&gt;函数添加一个&lt;code&gt;bool inverse&lt;/code&gt;参数，指定要使用正常的算法还是反向的算法。请你根据上述说明，完成反向的&lt;code&gt;LK&lt;/code&gt;光流法。&lt;/p&gt;

&lt;h4 id=&#34;答案-2&#34;&gt;答案：&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;正向和后向的区别在于关键点梯度的计算上面。正向是计算第二张片的梯度，后向是计算第一张图片的梯度。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最终结果如下（左为正向，右为后向）：
&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/视觉里程计-LK/single_f.png&#34; width=&#34;350&#34;&gt; &lt;img src=&#34;../images/视觉里程计-LK/single_i.png&#34;  width=&#34;350&#34;&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;最终结果如下（左为后向，右为opencv）：&lt;/p&gt;

&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/视觉里程计-LK/single_i.png&#34; width=&#34;350&#34;&gt; &lt;img src=&#34;../images/视觉里程计-LK/opencv_op.png&#34;  width=&#34;350&#34;&gt;
&lt;/div&gt;

&lt;h3 id=&#34;2-4-推广至金字塔&#34;&gt;2.4 推广至金字塔&lt;/h3&gt;

&lt;p&gt;通过实验，可以看出光流法通常只能估计几个像素内的误差。如果初始估计不够好，或者图像运动太大，光流法就无法得到有效的估计(不像特征点匹配那样)。但是，使用图像金字塔，可以让光流对图像运动不那么敏感。下面请你使用缩放倍率为2，共四层的图像金字塔，实现&lt;code&gt;coarse-to-fine&lt;/code&gt;的&lt;code&gt;LK&lt;/code&gt;光流。函数在&lt;code&gt;OpticalFlowMultiLevel&lt;/code&gt;中。&lt;/p&gt;

&lt;p&gt;实现完成后，给出你的光流截图(正向、反向、金字塔正向、金字塔反向)，可以和&lt;code&gt;OpenCV&lt;/code&gt;作比较。然后回答下列问题:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;所谓&lt;code&gt;coarse-to-fine&lt;/code&gt;是指怎样的过程？&lt;/li&gt;
&lt;li&gt;光流法中的金字塔用途和特征点法中的金字塔有何差别？
提示:你可以使用上面写的单层光流来帮助你实现多层光流。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;答案-3&#34;&gt;答案：&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;所谓的&lt;code&gt;coarse-to-fine&lt;/code&gt;是指：先跟踪金字塔的最顶层，然后用被跟踪帧在最顶层的跟踪结果，作为次顶层的跟踪初始值，再次进行跟踪，依次至第0层（原始图像）。相当于从低分辨率（对运动不敏感）的图像开始跟踪，向高精度图像进行逐层迭代，从而得到一个更为准确的关键点和光流的过程。&lt;/li&gt;
&lt;li&gt;光流法中的金字塔是逐层迭代寻找最佳的关键点位置和光流方向（像素梯度），目的是解决光流在运动过程中难以检测的问题；同时图像中的金字塔也是为了排除图像运动过快导致跟踪不上的问题，因此可以跟踪金字塔上层下采样后的图像，然后层层细化。
特征点法中的金字塔是通过逐层检测特征点来增加尺度描述，目的是解决特征点的尺度不变性问题。特征点中的金字塔是为了排除焦点距离的影响，即从远处看是一个特征点，但是近看时却不是，当近看时可以用金字塔的上面几层来跟踪，实现尺度的不变性。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最终结果如下：（左为正向，右为金字塔正向）
&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/视觉里程计-LK/single_f.png&#34; width=&#34;350&#34;&gt; &lt;img src=&#34;../images/视觉里程计-LK/multi_f.png&#34;  width=&#34;350&#34;&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;左为后向，右为金字塔后向：
&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/视觉里程计-LK/single_i.png&#34; width=&#34;350&#34;&gt; &lt;img src=&#34;../images/视觉里程计-LK/multi_i.png&#34;  width=&#34;350&#34;&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-5-讨论&#34;&gt;2.5 讨论&lt;/h3&gt;

&lt;p&gt;现在你已经自己实现了光流，看到了基于金字塔的&lt;code&gt;LK&lt;/code&gt;光流能够与&lt;code&gt;OpenCV&lt;/code&gt;达到相似的效果(甚至更好)。根据光流的结果，你可以和上讲一样，计算对极几何来估计相机运动。下面针对本次实验结果，谈谈你对下面问题的看法：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;我们优化两个图像块的灰度之差真的合理吗？哪些时候不够合理？你有解决办法吗？&lt;/li&gt;
&lt;li&gt;图像块大小是否有明显差异？取$16 \times 16 $和$8 \times 8$的图像块会让结果发生变化吗？&lt;/li&gt;
&lt;li&gt;金字塔层数对结果有怎样的影响?缩放倍率呢？&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;答案-4&#34;&gt;答案：&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;光流法有三个基本的假设：a：灰度不变假设；b：小运动假设；c：局部一致性假设。
其中，灰度不变假设，当相机存在自动曝光或者当物体有强光或者阴影时，灰度不变的建设是不成立的。通常的解决办法是，对相机进行光度模型标定，将图像校正到一致的状态。
本题中金字塔的方法是对运动较大时的一种解决方法。&lt;/li&gt;
&lt;li&gt;当采用了金字塔的方法时，窗口固定，将图像生成金字塔过程中，在每一层金字塔上都用同一个大小的窗口来进行光流计算，这样很好的去解决了图像块的问题，这样一来图像块大小并不会带来明显差异。&lt;br /&gt;
当没有采用金字塔方法时。当窗口较大时，光流计算更鲁棒，当窗口较小时，光流计算更正确。原因在于，当图像中每一个部分的运动都不一致的时候，如果开的窗口过大，很容易违背窗口(邻域)内的所有点光流一致的基本假设，这可能与实际不一致，所以窗口小，包含的像素少，更精确些。&lt;br /&gt;
在本题中，当图像块从$8×8$调到$16×16$，多层金字塔效果不明显，单程&lt;code&gt;IAIA&lt;/code&gt;效果略有改善。&lt;/li&gt;
&lt;li&gt;金字塔层数一般越多效果越好，但是一般图像大于4~5层之后都变得太小，特征点像素太过紧密容易出现错误追踪。放大倍率同样的道理，放大倍率小，金字塔的层数可以增加，迭代层数增多，效果自然要好。
对于本题中，将金字塔数从4层改为6层，结果基本无差别；将4层的缩放倍率从0.5改为0.25，结果基本无差别。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;完整程序链接：&lt;a href=&#34;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/optical_flow&#34;&gt;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/optical_flow&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;本题相关完整代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;inline float GetPixelValue(const cv::Mat &amp;amp;img, float x, float y) 
{
    uchar *data = &amp;amp;img.data[int(y) * img.step + int(x)];
    float xx = x - floor(x);
    float yy = y - floor(y);
    return float(
            (1 - xx) * (1 - yy) * data[0] +
            xx * (1 - yy) * data[1] +
            (1 - xx) * yy * data[img.step] +
            xx * yy * data[img.step + 1]
    );
}

int main(int argc, char **argv) {

    // images, note they are CV_8UC1, not CV_8UC3
    Mat img1 = imread(file_1, 0);
    Mat img2 = imread(file_2, 0);

    // key points, using GFTT here.
    vector&amp;lt;KeyPoint&amp;gt; kp1;
    Ptr&amp;lt;GFTTDetector&amp;gt; detector = GFTTDetector::create(500, 0.01, 20); // maximum 500 keypoints
    detector-&amp;gt;detect(img1, kp1);

    // now lets track these key points in the second image
    // first use single level LK in the validation picture
    vector&amp;lt;KeyPoint&amp;gt; kp2_single;
    vector&amp;lt;bool&amp;gt; success_single;
    OpticalFlowSingleLevel(img1, img2, kp1, kp2_single, success_single);

    // then test multi-level LK
    vector&amp;lt;KeyPoint&amp;gt; kp2_multi;
    vector&amp;lt;bool&amp;gt; success_multi;
    OpticalFlowMultiLevel(img1, img2, kp1, kp2_multi, success_multi);

    // use opencv&#39;s flow for validation
    vector&amp;lt;Point2f&amp;gt; pt1, pt2;
    for (auto &amp;amp;kp: kp1) pt1.push_back(kp.pt);
    vector&amp;lt;uchar&amp;gt; status;
    vector&amp;lt;float&amp;gt; error;
    cv::calcOpticalFlowPyrLK(img1, img2, pt1, pt2, status, error, cv::Size(8, 8));

    // plot the differences of those functions
    Mat img2_single;
    cv::cvtColor(img2, img2_single, CV_GRAY2BGR);
    for (int i = 0; i &amp;lt; kp2_single.size(); i++) {
        if (success_single[i]) {
            cv::circle(img2_single, kp2_single[i].pt, 2, cv::Scalar(0, 250, 0), 2);
            cv::line(img2_single, kp1[i].pt, kp2_single[i].pt, cv::Scalar(0, 250, 0));
        }
    }

    Mat img2_multi;
    cv::cvtColor(img2, img2_multi, CV_GRAY2BGR);
    for (int i = 0; i &amp;lt; kp2_multi.size(); i++) {
        if (success_multi[i]) {
            cv::circle(img2_multi, kp2_multi[i].pt, 2, cv::Scalar(0, 250, 0), 2);
            cv::line(img2_multi, kp1[i].pt, kp2_multi[i].pt, cv::Scalar(0, 250, 0));
        }
    }

    Mat img2_CV;
    cv::cvtColor(img2, img2_CV, CV_GRAY2BGR);
    for (int i = 0; i &amp;lt; pt2.size(); i++) {
        if (status[i]) {
            cv::circle(img2_CV, pt2[i], 2, cv::Scalar(0, 250, 0), 2);
            cv::line(img2_CV, pt1[i], pt2[i], cv::Scalar(0, 250, 0));
        }
    }

    cv::imshow(&amp;quot;tracked single level&amp;quot;, img2_single);
    cv::imwrite(&amp;quot;../single_i.png&amp;quot;, img2_single);
    cv::imshow(&amp;quot;tracked multi level&amp;quot;, img2_multi);
    cv::imwrite(&amp;quot;../multi_i.png&amp;quot;, img2_multi);
    cv::imshow(&amp;quot;tracked by opencv&amp;quot;, img2_CV);
    cv::imwrite(&amp;quot;../opencv_op.png&amp;quot;, img2_CV);
    cv::waitKey(0);

    return 0;
}

void OpticalFlowSingleLevel(
        const Mat &amp;amp;img1,
        const Mat &amp;amp;img2,
        const vector&amp;lt;KeyPoint&amp;gt; &amp;amp;kp1,
        vector&amp;lt;KeyPoint&amp;gt; &amp;amp;kp2,
        vector&amp;lt;bool&amp;gt; &amp;amp;success,
        bool inverse
) {

    // parameters
    int half_patch_size = 4;
    int iterations = 10;
    bool have_initial = !kp2.empty();

    for (size_t i = 0; i &amp;lt; kp1.size(); i++) 
    {
        auto kp = kp1[i];
        double dx = 0, dy = 0; // dx,dy need to be estimated
        if (have_initial) 
        {
            dx = kp2[i].pt.x - kp.pt.x;
            dy = kp2[i].pt.y - kp.pt.y;
        }

        double cost = 0, lastCost = 0;
        bool succ = true; // indicate if this point succeeded

        // Gauss-Newton iterations
        for (int iter = 0; iter &amp;lt; iterations; iter++) 
        {
            Eigen::Matrix2d H = Eigen::Matrix2d::Zero();
            Eigen::Vector2d b = Eigen::Vector2d::Zero();
            cost = 0;

            if (kp.pt.x + dx &amp;lt;= half_patch_size || kp.pt.x + dx &amp;gt;= img1.cols - half_patch_size ||
                kp.pt.y + dy &amp;lt;= half_patch_size || kp.pt.y + dy &amp;gt;= img1.rows - half_patch_size) 
            {   // go outside
                succ = false;
                break;
            }

            // compute cost and jacobian
            for (int x = -half_patch_size; x &amp;lt; half_patch_size; x++)
                for (int y = -half_patch_size; y &amp;lt; half_patch_size; y++) 
                {
                    double error = 0;
                    float u1 = float(kp.pt.x + x), v1 = float(kp.pt.y+y);
                    float u2 = float(u1+dx), v2 = float(v1+dy);
                    Eigen::Vector2d J;  // Jacobian
                    if (inverse == false) 
                    {
                        J.x() = double(GetPixelValue(img2,u2+1,v2) - GetPixelValue(img2,u2-1,v2))/2;
                        J.y() = double(GetPixelValue(img2,u2,v2+1) - GetPixelValue(img2,u2,v2-1))/2;
                        error = double(GetPixelValue(img2,u2,v2) - GetPixelValue(img1,u1,v1));
                        // Forward Jacobian
                    } else 
                    {
                        // Inverse Jacobian
                        // NOTE this J does not change when dx, dy is updated, so we can store it and only compute error
                        J.x() = double(GetPixelValue(img1,u1+1,v1) - GetPixelValue(img1,u1-1,v1))/2;
                        J.y() = double(GetPixelValue(img1,u1,v1+1) - GetPixelValue(img1,u1,v1-1))/2;
                        error = double(GetPixelValue(img2,u2,v2) - GetPixelValue(img1,u1,v1));
                    }

                    H += J*J.transpose();
                    b += -J*error;
                    cost += error*error;
                }

            // compute update
            Eigen::Vector2d update;
            update = H.ldlt().solve(b);

            if (isnan(update[0])) 
            {
                // sometimes occurred when we have a black or white patch and H is irreversible
                cout &amp;lt;&amp;lt; &amp;quot;update is nan&amp;quot; &amp;lt;&amp;lt; endl;
                succ = false;
                break;
            }
            if (iter &amp;gt; 0 &amp;amp;&amp;amp; cost &amp;gt; lastCost) 
            {
                cout &amp;lt;&amp;lt; &amp;quot;cost increased: &amp;quot; &amp;lt;&amp;lt; cost &amp;lt;&amp;lt; &amp;quot;, &amp;quot; &amp;lt;&amp;lt; lastCost &amp;lt;&amp;lt; endl;
                break;
            }

            // update dx, dy
            dx += update[0];
            dy += update[1];
            lastCost = cost;
            succ = true;
        }
        success.push_back(succ);
        // set kp2
        if (have_initial) 
        {
            kp2[i].pt = kp.pt + Point2f(dx, dy);
        } else 
        {
            KeyPoint tracked = kp;
            tracked.pt += cv::Point2f(dx, dy);
            kp2.push_back(tracked);
        }
    }
}

void OpticalFlowMultiLevel(
        const Mat &amp;amp;img1,
        const Mat &amp;amp;img2,
        const vector&amp;lt;KeyPoint&amp;gt; &amp;amp;kp1,
        vector&amp;lt;KeyPoint&amp;gt; &amp;amp;kp2,
        vector&amp;lt;bool&amp;gt; &amp;amp;success,
        bool inverse) {

    // parameters
    int pyramids = 4;
    double pyramid_scale = 0.5;
    double scales[] = {1.0, 0.5, 0.25, 0.125};

    // create pyramids
    vector&amp;lt;Mat&amp;gt; pyr1, pyr2; // image pyramids
    // TODO START YOUR CODE HERE (~8 lines)
    for (int i = 0; i &amp;lt; pyramids; i++) 
    {
        Mat img1_temp, img2_temp;
        resize(img1, img1_temp,Size(img1.cols*scales[i], img1.rows*scales[i]));
        resize(img2, img2_temp,Size(img2.cols*scales[i], img2.rows*scales[i]));
        pyr1.push_back(img1_temp);
        pyr2.push_back(img2_temp);
        cout&amp;lt;&amp;lt;&amp;quot;Pyramid&amp;quot;&amp;lt;&amp;lt;i&amp;lt;&amp;lt;&amp;quot;im1 size: &amp;quot;&amp;lt;&amp;lt;img1_temp.cols&amp;lt;&amp;lt;&amp;quot; &amp;quot; &amp;lt;&amp;lt;img1_temp.rows&amp;lt;&amp;lt;endl;
    }
    // coarse-to-fine LK tracking in pyramids
    vector&amp;lt;KeyPoint&amp;gt; vkp2_now;
    vector&amp;lt;KeyPoint&amp;gt; vkp2_last;
    vector&amp;lt;bool&amp;gt; vsucc;
    for(int i = pyramids-1;i&amp;gt;=0;i--)
    {
        vector&amp;lt;KeyPoint&amp;gt; vkp1;
        for(int j = 0; j&amp;lt;kp1.size();j++)
        {
            KeyPoint kp1_temp = kp1[j];
            kp1_temp.pt *= scales[i];
            vkp1.push_back(kp1_temp);
            if(i&amp;lt;pyramids-1)
            {
                KeyPoint kp2_temp = vkp2_last[j];
                kp2_temp.pt /= pyramid_scale;
                vkp2_now.push_back(kp2_temp);
            }
        }
        vsucc.clear();
        OpticalFlowSingleLevel(pyr1[i], pyr2[i], vkp1, vkp2_now, vsucc, inverse);
        vkp2_last.clear();
        vkp2_last.swap(vkp2_now);
        cout&amp;lt;&amp;lt;&amp;quot;pyramid: &amp;quot;&amp;lt;&amp;lt;i&amp;lt;&amp;lt;&amp;quot;vkp2_last size: &amp;quot;&amp;lt;&amp;lt;vkp2_last.size()&amp;lt;&amp;lt;&amp;quot;vkp2_noe size &amp;quot;&amp;lt;&amp;lt;vkp2_now.size()&amp;lt;&amp;lt;endl;
    }
    kp2 = vkp2_last;
    success = vsucc;
    // TODO END YOUR CODE HERE
    // don&#39;t forget to set the results into kp2
}
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>视觉里程计1</title>
      <link>https://xlmaverick.me/post/-%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A11/</link>
      <pubDate>Wed, 08 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://xlmaverick.me/post/-%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A11/</guid>
      
        <description>

&lt;h1 id=&#34;视觉里程计1&#34;&gt;视觉里程计1&lt;/h1&gt;

&lt;h2 id=&#34;习题二-从e恢复r-t&#34;&gt;习题二：从E恢复R，t&lt;/h2&gt;

&lt;p&gt;我们在书中讲到了单目对极几何部分，可以通过本质矩阵E，得到旋转和平移R，t，但那时直接使用了OpenCV提供的函数。本题中，请你根据数学原理，完成从E到R，t的计算。程序框架见&lt;code&gt;code/E2Rt.cpp&lt;/code&gt;。&lt;br /&gt;
设Essential矩阵E的取值为(与书上实验数值相同):&lt;/p&gt;

&lt;p&gt;
$$
E=\begin{bmatrix} −0.0203618550523477 &amp; −0.4007110038118445 &amp; −0.03324074249824097 \\ 0.3939270778216369 &amp; −0.03506401846698079 &amp; 0.5857110303721015 \\ −0.006788487241438284 &amp; −0.5815434272915686 &amp;−0.01438258684486258 \\ \end{bmatrix} 
$$
&lt;/p&gt;

&lt;p&gt;请计算对应的R，t，流程如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;对E作SVD分解：
$$
E = U \Sigma V^T
$$&lt;/li&gt;
&lt;li&gt;处理$\Sigma$的奇异值。设$\Sigma = diag(\sigma_1,\sigma_2,\sigma_3)$，并且$\sigma_1 \geq \sigma_2 \geq \sigma_3$，那么处理后的$\Sigma$为：
$$
\Sigma = diag(\frac{\sigma_1 + \sigma_2}{2}, \frac{\sigma_1 + \sigma_2}{2}, 0)
$$&lt;/li&gt;
&lt;li&gt;共存在四个可能的解：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;
$$
t_1^{∧} = UR_{Z(\frac{\pi}{2})}\Sigma U^T, R_1 = UR_{Z(\frac{\pi}{2})}V^T  \\
t_2^{∧} = UR_{Z(-\frac{\pi}{2})}\Sigma U^T, R_2 = UR_{Z(-\frac{\pi}{2})}V^T  
$$
&lt;/p&gt;

&lt;p&gt;其中$R_{Z(\frac{\pi}{2})}$表示沿Z轴旋转90度得到的旋转矩阵。同时，由于-E和E等价，所以对任意的一个t或R取负号，也会得到同样的结果。因此，从E分解到t，R时，一共存在四个可能的解。请打印出这四个可能的R，t。&lt;/p&gt;

&lt;h3 id=&#34;提示&#34;&gt;提示&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;用&lt;code&gt;AngleAxis&lt;/code&gt;或&lt;code&gt;Sophus::SO3&lt;/code&gt;计算$R_{Z(\frac{\pi}{2})}$。&lt;/li&gt;
&lt;li&gt;实际当中，可以利用深度值判断哪个解是真正的解，不过本题不作要求，只需打印四个可能的解即可。同时，你也可以验证$t^∧R$应该与E只差一个乘法因子，并且与书上的实验结果亦只差一个乘法因子。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;答案&#34;&gt;答案&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;本质矩阵&lt;code&gt;E&lt;/code&gt;的奇异值必定是$[\sigma , \sigma , 0]$，这是本质矩阵的内在性质。&lt;/li&gt;
&lt;li&gt;本质矩阵 $E = t^{\bigwedge} *R$，但是由于尺度等价性，他的自由度只有5。&lt;/li&gt;
&lt;li&gt;此处还得注意本质矩阵和但应矩阵的对比，这一点后续还会补充。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最终的结果为：
&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/视觉里程计1/result.png&#34;&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;完整程序链接：&lt;a href=&#34;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/computerRt&#34;&gt;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/computerRt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;相关代码为&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    int main(int argc, char **argv) {

        // 给定Essential矩阵
        Matrix3d E;
        E &amp;lt;&amp;lt; -0.0203618550523477, -0.4007110038118445, -0.03324074249824097,
                0.3939270778216369, -0.03506401846698079, 0.5857110303721015,
                -0.006788487241438284, -0.5815434272915686, -0.01438258684486258;

        // 待计算的R,t
        Matrix3d R;
        Vector3d t;

        JacobiSVD&amp;lt;MatrixXd&amp;gt; svd(E,ComputeThinU | ComputeThinV);
        Matrix3d U = svd.matrixU();
        Matrix3d V = svd.matrixV();
        Matrix3d Sigma = U.inverse()*E*V.transpose().inverse();
        // cout&amp;lt;&amp;lt;&amp;quot;U:\n&amp;quot;&amp;lt;&amp;lt;U&amp;lt;&amp;lt;&amp;quot;\nV:\n&amp;quot;&amp;lt;&amp;lt;V&amp;lt;&amp;lt;&amp;quot;\nSigma:\n&amp;quot;&amp;lt;&amp;lt;Sigma&amp;lt;&amp;lt;endl;
        vector&amp;lt;double&amp;gt;  tao = {Sigma(0,0),Sigma(1,1),Sigma(2,2)};
        sort(tao.begin(), tao.end());
        Matrix3d SigmaFix = Matrix3d::Zero();
        double tao_mead = (tao[1]+tao[2])*0.5;
        SigmaFix(0,0) = tao_mead;
        SigmaFix(1,1) = tao_mead;
        cout&amp;lt;&amp;lt;&amp;quot;Sigma after fix: \n&amp;quot;&amp;lt;&amp;lt;SigmaFix&amp;lt;&amp;lt;endl;

        Matrix3d R_Z1 = AngleAxisd(M_PI/2, Vector3d(0,0,1)).matrix();
        Matrix3d R_Z2 = AngleAxisd(-M_PI/2, Vector3d(0,0,1)).matrix();

        Matrix3d t_wedge1 = U*R_Z1*SigmaFix*U.transpose();
        Matrix3d t_wedge2 = U*R_Z2*SigmaFix*U.transpose();

        Matrix3d R1 = U*R_Z1*V.transpose();
        Matrix3d R2 = U*R_Z2*V.transpose(); 


        cout &amp;lt;&amp;lt; &amp;quot;R1 = &amp;quot; &amp;lt;&amp;lt; endl&amp;lt;&amp;lt;R1 &amp;lt;&amp;lt; endl;
        cout &amp;lt;&amp;lt; &amp;quot;R2 = &amp;quot; &amp;lt;&amp;lt; endl&amp;lt;&amp;lt;R2 &amp;lt;&amp;lt; endl;
        cout &amp;lt;&amp;lt; &amp;quot;t1 = &amp;quot; &amp;lt;&amp;lt;endl&amp;lt;&amp;lt; Sophus::SO3::vee(t_wedge1) &amp;lt;&amp;lt; endl;
        cout &amp;lt;&amp;lt; &amp;quot;t2 = &amp;quot; &amp;lt;&amp;lt;endl&amp;lt;&amp;lt; Sophus::SO3::vee(t_wedge2) &amp;lt;&amp;lt; endl;

        // check t^R=E up to scale
        Matrix3d tR = t_wedge1 * R1;
        cout &amp;lt;&amp;lt; &amp;quot;t^R = &amp;quot; &amp;lt;&amp;lt; tR &amp;lt;&amp;lt; endl;

        return 0;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;习题三-用g-n实现bundle-adjustment&#34;&gt;习题三：用G-N实现Bundle Adjustment&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;Bundle Adjustment&lt;/code&gt;并不神秘，它仅是一个目标函数为重投影误差的最小二乘。我们演示了&lt;code&gt;Bundle Adjustment&lt;/code&gt;可以由&lt;code&gt;Ceres&lt;/code&gt;和&lt;code&gt;g2o&lt;/code&gt;实现，并可用于&lt;code&gt;PnP&lt;/code&gt;当中的位姿估计。本题，你需要自己书写一个高斯牛顿法，实现用&lt;code&gt;Bundle Adjustment&lt;/code&gt;优化位姿的功能，求出相机位姿。严格来说，这是&lt;code&gt;Bundle Adjustment&lt;/code&gt;的一部分，因为我们仅考虑了位姿，没有考虑点的更新。完整的BA需要用到矩阵的稀疏性，我们留到第七节课介绍。&lt;br /&gt;
假设一组点的3D坐标为$P = {p_i}$，它们在相机中的坐标为$U = {u_i},∀i = 1, &amp;hellip; n$。在文件 &lt;code&gt;p3d.txt&lt;/code&gt;和&lt;code&gt;p2d.txt&lt;/code&gt;中给出了这两组点的值。同时，设待估计的位姿为$T ∈ SE(3)$，内参矩阵为：&lt;/p&gt;

&lt;p&gt;$$
K =  \begin{bmatrix} 520.9 &amp;amp; 0 &amp;amp; 325.1 \\
                     521.0 &amp;amp; 249.7 &amp;amp; 0 \\
                     1 &amp;amp; 0 &amp;amp; 0\&lt;br /&gt;
                     \end{bmatrix}
$$&lt;/p&gt;

&lt;p&gt;请你根据上述条件，用G-N法求出最优位姿，初始估计为$T_0 = I$。程序&lt;code&gt;GN-BA.cpp&lt;/code&gt;文件提供了大致的框架,请填写剩下的内容。
在书写程序过程中,回答下列问题:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;如何定义重投影误差?&lt;/li&gt;
&lt;li&gt;该误差关于自变量的雅可比矩阵是什么?&lt;/li&gt;
&lt;li&gt;解出更新量之后,如何更新至之前的估计上?&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;作为验证,最后估计得到的位姿应该接近:&lt;/p&gt;

&lt;p&gt;
$$
T^* = \begin{bmatrix} 0.9978 &amp; 0.0506 &amp; 0.0399 &amp; −0.1272 \\\\
                      0.0506 &amp;  0.9983 &amp; 0.0274 &amp; −0.007 \\\\
                      −0.0412 &amp; −0.0253 &amp; 0.9977 &amp; 0.0617 \\\\
                       0 &amp; 0 &amp; 0 &amp; 1 \\\\
                        \end{bmatrix}
$$
&lt;/p&gt;

&lt;p&gt;这和书中使用&lt;code&gt;g2o&lt;/code&gt;优化的结果很接近。&lt;/p&gt;

&lt;h3 id=&#34;答案-1&#34;&gt;答案&lt;/h3&gt;

&lt;p&gt;1.首先我们需要明白&lt;code&gt;PnP&lt;/code&gt;问题是的已知条件&lt;code&gt;3D&lt;/code&gt;点以及在图像中的投影坐标，整个误差函数的简历是相机模型中坐标系的变换，利用归一化坐标系下的坐标作为中间变量，链式求导，进而求解雅各比矩阵的。整个过程是针对一帧而言。这和直接法中的不一样，直接法是前后两帧。&lt;br /&gt;
重投影误差定义为：&lt;/p&gt;

&lt;p&gt;
$$
e(\xi)=P_{u v}-\frac{1}{z_{c}} \operatorname{Kexp}\left(\xi^{\wedge}\right) P_{w}
$$
&lt;/p&gt;

&lt;p&gt;2.关于误差的雅各比矩阵有两部分组成，误差关于重投影点的导数、变换后的点关于李代数的导数：&lt;/p&gt;

&lt;p&gt;
$$
J(\xi)=-\left[ \begin{array}{ccccc}{\frac{f_{x}}{z_{c}}} &amp; {0} &amp; {-\frac{f_{x} x_{c}}{z_{c}^{2}}} &amp; {-\frac{f_{x} x_{c} y_{c}}{z_{c}^{2}}} &amp; {f_{x}+\frac{f_{x} x_{c}^{2}}{Z_{c}^{2}}} &amp; {-\frac{f_{x} y_{c}}{z_{c}}} \\ {0} &amp; {\frac{f_{y}}{z_{c}}} &amp; {-\frac{f_{y} y_{c}}{z_{c}^{2}}} &amp; {-f_{y}-\frac{f_{y} y_{c}^{2}}{z_{c}^{2}}} &amp; {\frac{f_{y} x_{c} y_{c}}{z_{c}^{2}}} &amp; {\frac{f_{y} x_{c}}{z_{c}}}\end{array}\right]
$$
&lt;/p&gt;

&lt;p&gt;3.解出更新量之后，更新至之前的估计上有两种方式，李代数上或者在变换矩阵上：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    T21 = Sophus::SE3::exp(update) * T21;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;或者&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    Vector6d T_origin = T_esti.log();
    Vector6d T_se = (T_origin + dx);
    T_esti = Sophus::SE3::exp(T_se);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终结果为：
&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/视觉里程计1/result-ba.png&#34;&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;完整程序链接：&lt;a href=&#34;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/BApnp&#34;&gt;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/BApnp&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;相关代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    int main(int argc, char **argv) {
        VecVector2d p2d;
        VecVector3d p3d;
        Matrix3d K;
        double fx = 520.9, fy = 521.0, cx = 325.1, cy = 249.7;
        K &amp;lt;&amp;lt; fx, 0, cx, 0, fy, cy, 0, 0, 1;

        ifstream p3dfile;
        p3dfile.open(p3d_file);
        if(!p3dfile)
        {
            cout&amp;lt;&amp;lt;&amp;quot;open p3d.txt error!&amp;quot;&amp;lt;&amp;lt;endl;
        }
        string p3dline;
        while(getline(p3dfile,p3dline) &amp;amp;&amp;amp; !p3dline.empty())
        {
            istringstream p3dtempLine(p3dline);
            Vector3d p3dtemp;
            p3dtempLine&amp;gt;&amp;gt;p3dtemp[0]&amp;gt;&amp;gt;p3dtemp[1]&amp;gt;&amp;gt;p3dtemp[2];
            p3d.push_back(p3dtemp);
            
        }        
        ifstream p2dfile;
        p2dfile.open(p2d_file);
        if(!p2dfile)
        {
            cout&amp;lt;&amp;lt;&amp;quot;open p2d.txt error!&amp;quot;&amp;lt;&amp;lt;endl;
        }
        string p2dline;
        while(getline(p2dfile,p2dline) &amp;amp;&amp;amp; !p2dline.empty())
        {
            istringstream p2dtempLine(p2dline);
            Vector2d p2dtemp;
            p2dtempLine&amp;gt;&amp;gt;p2dtemp[0]&amp;gt;&amp;gt;p2dtemp[1];
            p2d.push_back(p2dtemp);
            
        }
        assert(p3d.size() == p2d.size());
        int iterations = 100;
        double cost = 0, lastCost = 0;
        int nPoints = p3d.size();
        cout &amp;lt;&amp;lt; &amp;quot;points: &amp;quot; &amp;lt;&amp;lt; nPoints &amp;lt;&amp;lt; endl;
        Sophus::SE3 T_esti(Matrix3d::Identity(),Vector3d::Zero()); // estimated pose
        for (int iter = 0; iter &amp;lt; iterations; iter++) 
        {
            Matrix&amp;lt;double, 6, 6&amp;gt; H = Matrix&amp;lt;double, 6, 6&amp;gt;::Zero();
            Vector6d b = Vector6d::Zero();
            Vector2d e;
            cost = 0;
            for (int i = 0; i &amp;lt; nPoints; i++) 
            {
                Vector3d pc = T_esti*p3d[i];
                Vector3d e_temp = Vector3d(p2d[i][0],p2d[i][1],1) - K*pc/pc[2];
                e[0] = e_temp[0];
                e[1] = e_temp[1];
                cost  += 0.5*e.transpose()*e; 
                double x = pc[0], y = pc[1], z = pc[2];
                Matrix&amp;lt;double, 2, 6&amp;gt; J;
                J(0,0) = -fx/z;
                J(0,2) = fx*x/(z*z);
                J(0,3) = fx*x*y/(z*z);
                J(0,4) = -fx - fx*(x*x)/(z*z);
                J(0,5) =  fx*y/z;
                J(1,1) = -fy/z;
                J(1,2) = fy*y/(z*z);
                J(1,3) = fy+fy*(y*y)/(z*z);
                J(1,4) = -fy*x*y/(z*z);
                J(1,5) = -fy*x/z;

                H +=J.transpose()*J;
                b +=-J.transpose()*e;
            }
            Vector6d dx;
            dx = H.ldlt().solve(b);

            if (isnan(dx[0])) 
            {
                cout &amp;lt;&amp;lt; &amp;quot;result is nan!&amp;quot; &amp;lt;&amp;lt; endl;
                break;
            }
            if (iter &amp;gt; 0 &amp;amp;&amp;amp; cost &amp;gt;= lastCost) 
            {
                // cost increase, update is not good
                cout &amp;lt;&amp;lt; &amp;quot;cost: &amp;quot; &amp;lt;&amp;lt; cost &amp;lt;&amp;lt; &amp;quot;, last cost: &amp;quot; &amp;lt;&amp;lt; lastCost &amp;lt;&amp;lt; endl;
                break;
            }
            T_esti = Sophus::SE3::exp(dx)*T_esti;            
            lastCost = cost;
            cout &amp;lt;&amp;lt; &amp;quot;iteration &amp;quot; &amp;lt;&amp;lt; iter &amp;lt;&amp;lt; &amp;quot; cost=&amp;quot; &amp;lt;&amp;lt; cout.precision(12) &amp;lt;&amp;lt; cost &amp;lt;&amp;lt; endl;
        }
        cout &amp;lt;&amp;lt; &amp;quot;estimated pose: \n&amp;quot; &amp;lt;&amp;lt; T_esti.matrix() &amp;lt;&amp;lt; endl;
        return 0;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;习题三-用icp实现轨迹对齐&#34;&gt;习题三：用ICP实现轨迹对齐&lt;/h2&gt;

&lt;p&gt;在实际当中，我们经常需要比较两条轨迹之间的误差。第三节课习题中，你已经完成了两条轨迹之间的&lt;code&gt;RMSE&lt;/code&gt; 误差计算。但是，由于&lt;code&gt;ground-truth&lt;/code&gt;轨迹与相机轨迹很可能不在一个参考系中，它们得到的轨迹并不能直接比较。这时，我们可以用&lt;code&gt;ICP&lt;/code&gt;来计算两条轨迹之间的相对旋转与平移，从而估计出两个参考系之间的差异。
设真实轨迹为 $T_ g$ ，估计轨迹为 $T_ e$ ，二者皆以 $T_ {WC}$ 格式存储。但是真实轨迹的坐标原点定义于外部
某参考系中（取决于真实轨迹的采集方式，如&lt;code&gt;Vicon&lt;/code&gt;系统可能以某摄像头中心为参考系，而估计轨迹则以相机出发点为参考系（在视觉&lt;code&gt;SLAM&lt;/code&gt;中很常见）。由于这个原因，理论上的真实轨迹点与估计轨迹点应满足：&lt;/p&gt;

&lt;p&gt;
$$
\mathbf{T}_{g, i}=\mathbf{T}_{g e} \mathbf{T}_{e, i}
$$
&lt;/p&gt;

&lt;p&gt;其中&lt;code&gt;i&lt;/code&gt;表示轨迹中的第&lt;code&gt;i&lt;/code&gt;条记录，$T_ {ge} ∈ SE(3)$为两个坐标系之间的变换矩阵，该矩阵在整条轨迹中保持不变。$T_ {ge}$可以通过两条轨迹数据估计得到，但方法可能有若干种：&lt;/p&gt;

&lt;p&gt;1.认为初始化时两个坐标系的差异就是$T_{ge}，即：&lt;/p&gt;

&lt;p&gt;
$$
\mathbf{T}_{g e}=\mathbf{T}_{g, 1} \mathbf{T}_{e, 1}^{-1}
$$
&lt;/p&gt;

&lt;p&gt;2.在整条轨迹上利用最小二乘计算$T_ge$：&lt;/p&gt;

&lt;p&gt;
$$
\mathbf{T}_{g e}=\arg \min _{\mathbf{T}_{g c}} \sum_{i=1}^{n}\left\|\log \left(\mathbf{T}_{g i}^{-1} \mathbf{T}_{g e} \mathbf{T}_{e, i}\right)^{\mathrm{v}}\right\|_{2}
$$
&lt;/p&gt;

&lt;p&gt;3.把两条轨迹的平移部分看作点集，然后求点集之间的&lt;code&gt;ICP&lt;/code&gt;，得到两组点之间的变换。&lt;/p&gt;

&lt;p&gt;其中第三种也是实践中用的最广的一种。现在请你书写&lt;code&gt;ICP&lt;/code&gt;程序，估计两条轨迹之间的差异。轨迹文
件在&lt;code&gt;compare.txt&lt;/code&gt;文件中，格式为：&lt;/p&gt;

&lt;p&gt;
$$
_{e}, \mathbf{t}_{e}, \mathbf{q}_{e}, \text { time }_{g}, \mathbf{t}_{g}, \mathbf{q}_{g}
$$
&lt;/p&gt;

&lt;p&gt;其中&lt;code&gt;t&lt;/code&gt;表示平移，&lt;code&gt;q&lt;/code&gt;表示单位四元数。请计算两条轨迹之间的变换，然后将它们统一到一个参考系，并画在&lt;code&gt;pangolin&lt;/code&gt;中。轨迹的格式与先前相同，即以时间，平移，旋转四元数方式存储。
本题不提供代码框架,你可以利用之前的作业完成本题。&lt;/p&gt;

&lt;h3 id=&#34;答案-2&#34;&gt;答案：&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;ICP&lt;/code&gt;有两种解决办法，&lt;code&gt;SVD&lt;/code&gt;和非线性优化的方法，这一次我们尝试两种办法，其中非线性优化的方法我们采用&lt;code&gt;g2o&lt;/code&gt;优化库。&lt;/li&gt;
&lt;li&gt;画图部分依然采用&lt;code&gt;pangolin&lt;/code&gt;，和前几讲的方式一样。&lt;/li&gt;
&lt;li&gt;g2o的版本问题需要注意，最新版本有些地方是不兼容的。&lt;/li&gt;
&lt;li&gt;还是g2o的问题，g2o中李代数的定义顺序和我们一样不一样。通常前三维为平移，后三维为旋转，但是&lt;code&gt;g2o&lt;/code&gt;的李代数和&lt;code&gt;Sohpus&lt;/code&gt;的李代数定义就不一样，g2o中是前三维为旋转，后三维为平移，所以对应的雅各比矩阵交换了顺序，这一点尤其需要注意。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;首先是SVD方法的结果：
&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/视觉里程计1/原始图像.png&#34; width=&#39;350&#39;&gt; &lt;img src=&#34;../images/视觉里程计1/svd_result.png&#34; width=&#39;350&#39;&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/视觉里程计1/svd_result1.png&#34;&gt;
&lt;/div&gt;

&lt;p&gt;非线性优化的结果：
&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/视觉里程计1/原始图像.png&#34; width=&#39;350&#39;&gt; &lt;img src=&#34;../images/视觉里程计1/ba_result.png&#34; width=&#39;350&#39;&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/视觉里程计1/ba_result1.png&#34;&gt;
&lt;/div&gt;

&lt;p&gt;完整程序链接：&lt;a href=&#34;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/icp&#34;&gt;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/icp&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>视觉里程计1-ORB</title>
      <link>https://xlmaverick.me/post/-%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A11-orb/</link>
      <pubDate>Mon, 06 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://xlmaverick.me/post/-%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A11-orb/</guid>
      
        <description>

&lt;h1 id=&#34;视觉里程计1&#34;&gt;视觉里程计1&lt;/h1&gt;

&lt;h2 id=&#34;习题一-orb特征点&#34;&gt;习题一：ORB特征点&lt;/h2&gt;

&lt;p&gt;ORB(Oriented FAST and BRIEF)特征是SLAM中一种很常用的特征,由于其二进制特性,使得它可以非常快速地提取与计算。下面,你将按照本题的指导,自行书写ORB的提取、描述子的计算以及匹配的代码。代码框架参照computeORB.cpp文件，图像见1.png文件和2.png。&lt;/p&gt;

&lt;h3 id=&#34;1-1-orb提取&#34;&gt;1.1 ORB提取&lt;/h3&gt;

&lt;p&gt;ORB即Oriented FAST简称。它实际上是FAST特征再加上一个旋转量。本习题将使用OpenCV自带的FAST提取算法,但是你要完成旋转部分的计算。旋转的计算过程描述如下：&lt;br /&gt;
在一个小图像块中，先计算质心。质心是指以图像块灰度值作为权重的中心。&lt;/p&gt;

&lt;p&gt;1.在一个小的的图像块B中，定义图像块的距为：&lt;/p&gt;

&lt;p&gt;
$$
m_{pq} = \sum_{x,y\in B}x^py^qI(x,y),p,q=\begin{Bmatrix} 0,&amp;1 \end{Bmatrix}
$$
&lt;/p&gt;

&lt;p&gt;2.通过矩可以找到图像块的质心：&lt;/p&gt;

&lt;p&gt;
$$
C=(\frac{m_{10}}{m_{00}},\frac{m_{01}}{m_{00}})
$$
&lt;/p&gt;

&lt;p&gt;3.连接图像块的几何中心$O$和质心$C$，可以得到一个方向向量$\overrightarrow{OC}$，于是特征点的方向可以定义为：&lt;/p&gt;

&lt;p&gt;
$$
\theta = arctan(\frac{m_{01}}{m_{10}})
$$
&lt;/p&gt;

&lt;p&gt;实际上只需计算$m_ {01}$和$m_{10}$即可。习题中取图像块大小为$16\times16$，即对于任意点$(u,v)$，图像块从$(u−8,v−8)$取到$(u+7,v+7)$即可。请在习题的computeAngle中，为所有特征点计算这个旋转角。&lt;/p&gt;

&lt;h4 id=&#34;提示&#34;&gt;提示&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;由于要取图像$16\times16$块，所以位于边缘处的点(比如$u&amp;lt;8$的)对应的图像块可能会出界,此时需要判断该点是否在边缘处,并跳过这些点。&lt;/li&gt;
&lt;li&gt;由于矩的定义方式,在画图特征点之后，角度看起来总是指向图像中更亮的地方。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;std::atan&lt;/code&gt;和&lt;code&gt;std::atan2&lt;/code&gt;会返回弧度制的旋转角，但OpenCV中使用角度制，如使用&lt;code&gt;std::atan&lt;/code&gt;类函数,请转换一下。&lt;/li&gt;
&lt;li&gt;Opencv中row、col和Point中的x、y是相反的，这个需要注意，即Mat是行列的顺序，point是列行的顺序。
&lt;code&gt;
row == heigh == Point.y //行
col == width == Point.x //列
Mat::at(Point(x, y)) == Mat::at(y,x)
&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;计算质心的公式中的&lt;code&gt;x，y&lt;/code&gt;是$-8,7$，不是图像中关键点的坐标，这一点需要注意，下面计算描述子的时候也是一样的。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-2-orb描述&#34;&gt;1.2 ORB描述&lt;/h3&gt;

&lt;p&gt;ORB描述即带旋转的BRIEF描述。所谓BRIEF描述是指一个$0-1$组成的字符串(可以取256位或128位)，每一个&lt;code&gt;bit&lt;/code&gt;表示一次像素间的比较。算法流程如下:&lt;/p&gt;

&lt;p&gt;1.给定图像$I$和关键点 $(u,v)$ ，以及该点的转角$θ$。以256位描述为例，那么最终描述子&lt;/p&gt;

&lt;p&gt;
$$
d = [d_1,d_2, \cdots , d_{256} ]
$$
&lt;/p&gt;

&lt;p&gt;2.对任意$i=1,\cdots,256,d_i$的计算如下。取$(u,v)$附近任意两个点$p,q$，并按照$θ$进行旋转:&lt;/p&gt;

&lt;p&gt;
$$
\begin{bmatrix} u_p^{&#39;}  \\ v_p^{&#39;} \\ \end{bmatrix} = 
\begin{bmatrix} cosθ &amp; −sinθ \\ sinθ &amp; cosθ \\ \end{bmatrix} 
\begin{bmatrix} u_p  \\ v_p \\ \end{bmatrix}
$$
&lt;/p&gt;

&lt;p&gt;其中$u_p,v_p$为$p$的坐标，对$q$亦然。记旋转后的$p,q$为$p^′,q^′$，那么比较$I(p^′)$和$I(q^′)$，若前者大，记$d_i=0$，反之记$d_i=1$。&lt;/p&gt;

&lt;p&gt;这样我们就得到了ORB的描述。我们在程序中用256个&lt;code&gt;bool&lt;/code&gt;变量表达这个描述。请你完&lt;code&gt;compute-ORBDesc&lt;/code&gt; 函数,实现此处计算。注意，通常我们会固定$p,q$的取法(称为&lt;code&gt;ORB&lt;/code&gt;的&lt;code&gt;pattern&lt;/code&gt;)，否则每次都重新随机选取，会使得描述不稳定。我们在全局变量&lt;code&gt;ORB_pattern&lt;/code&gt;中定义了$p,q$的取法，格式为$u_p,v_p,u_q,v-q$。请你根据给定的&lt;code&gt;pattern&lt;/code&gt;完成&lt;code&gt;ORB&lt;/code&gt;描述的计算。&lt;/p&gt;

&lt;h4 id=&#34;提示-1&#34;&gt;提示&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;$p,q$同样要做边界检查，否则会跑出图像外。如果跑出图像外，就设这个描述子为空。&lt;/li&gt;
&lt;li&gt;调用&lt;code&gt;cos&lt;/code&gt;和&lt;code&gt;sin&lt;/code&gt;时同样请注意弧度和角度的转换。&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-3-暴力匹配&#34;&gt;1.3 暴力匹配&lt;/h3&gt;

&lt;p&gt;在提取描述之后，我们需要根据描述子进行匹配。暴力匹配是一种简单粗暴的匹配方法，在特征点不多时很有用。下面你将根据习题指导,书写暴力匹配算法。&lt;br /&gt;
所谓暴力匹配思路很简单。给定两组描述子$P=[p_1, \cdots, p_M]$和$Q=[q_1, \cdots,q_N]$。那么,对$P$中任意一个点,找到$Q$中对应最小距离点，即算一次匹配。但是这样做会对每个特征点都找到一个匹配,所以我们通常还会限制一个距离阈值$d_max$，即认作匹配的特征点距离不应该大于$d_max$。下面请你根据上述描述,实现函数&lt;code&gt;bfMatch&lt;/code&gt;，返回给定特征点的匹配情况。实践中取$d_max = 50$。
最后,请结合实验,回答下面几个问题:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;为什么说 ORB 是一种二进制特征？&lt;/li&gt;
&lt;li&gt;为什么在匹配时使用 50 作为阈值，取更大或更小值会怎么样？&lt;/li&gt;
&lt;li&gt;暴力匹配在你的机器上表现如何?你能想到什么减少计算量的匹配方法吗？&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;提示-2&#34;&gt;提示&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;你需要按位计算两个描述子之间的汉明距离。汉明距离的定义是两个描述子中不相同的个数。&lt;/li&gt;
&lt;li&gt;OpenCV的&lt;code&gt;DMatch&lt;/code&gt;结构，&lt;code&gt;queryIdx&lt;/code&gt;为第一图的特征ID，&lt;code&gt;trainIdx&lt;/code&gt;为第二个图的特征 ID。&lt;/li&gt;
&lt;li&gt;在这个函数中用到了&lt;code&gt;sort&lt;/code&gt;函数对二维数组的排序操作，&lt;code&gt;sort&lt;/code&gt;函数可以制定维度对多维数组进行排序，未指定则默认为第一维。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;答案&#34;&gt;答案&lt;/h3&gt;

&lt;p&gt;最前面先回答实验的问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ORB 的描述子是用许多对像素点坐标(此处坐标需要经过旋转校正，就是第二问用到的公式)所在位置的灰度值的大小对比来组成,对比结果为0和1，假设有256对像素点，那么ORB的特征点描述子便有256个0或1组成,因此称ORB是一种二进制特征;&lt;/li&gt;
&lt;li&gt;ORB 匹配时是计算两个描述子之前的汉明距离,即计算两个二进制值在每一位上不相等的个数,当然我们希望这个不相等的个数越少越好,当个数为 0,则说明两个描述子的特征完全一致,随着个数越多,说明两个特征不一致的程度也就越高,因此若将阈值取小,则匹配点对的数量越少,但是误匹配几率越小,反之,若将阈值调高,则匹配出的点对数量增加,但误匹配几率也增加。&lt;/li&gt;
&lt;li&gt;匹配117对点。耗时为3.964秒。若在 CMakeLists 中增加-O2 编译优化,则耗时可减小至0.19秒。若改为-O3 编译优化,耗时可继续减小至0.186221秒。&lt;br /&gt;
另外一种办法是减少计算量,可以使用 FLANN 快速近似最近邻算法。&lt;br /&gt;
这个具体是编译优化的问题，在&lt;code&gt;Visual Studio&lt;/code&gt;中我们可以生成&lt;code&gt;debug&lt;/code&gt;版和&lt;code&gt;release&lt;/code&gt;版的程序,使用&lt;code&gt;CMake&lt;/code&gt;我们也可以达到上述效果。debug 版的项目生成的可执行文件需要有调试信息并且不需要进行优化,而 release 版的不需要调试信息但需要优化。这些特性在 gcc/g++ 中是通过编译时的参数来决定的,如果将优化程度调到最高需要设置参数&lt;code&gt;-O3&lt;/code&gt;，最低是&lt;code&gt;-O0&lt;/code&gt;，即不做优化；添加调试信息的参数是&lt;code&gt;-g -ggdb&lt;/code&gt;，如果不添加这个参数，调试信息就不会被包含在生成的二进制文件中。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最终结果如下：
&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/视觉历程计-ORB/feat1.png&#34;&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;匹配结果如下：
&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/视觉历程计-ORB/matches.png&#34;&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;完整程序链接：&lt;a href=&#34;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/computeORB&#34;&gt;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/computeORB&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;1.ORB增加旋转的最终结果如下：再强调一遍注意看第一问的提示部分。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    void computeAngle(const cv::Mat &amp;amp;image, vector&amp;lt;cv::KeyPoint&amp;gt; &amp;amp;keypoints) 
    {
        int half_patch_size = 8;
        for(auto&amp;amp; kp:keypoints)
        {
            int u = kp.pt.x;
            int v = kp.pt.y;
            if(u-8&amp;lt;0 || u+8&amp;gt;=image.cols || v-8&amp;lt;0 || v+8 &amp;gt;= image.rows)
            {
                cout&amp;lt;&amp;lt;&amp;quot;Keypoint is out of range&amp;quot;&amp;lt;&amp;lt;kp.pt&amp;lt;&amp;lt;endl;
                continue;
            }
            int m01 = 0;
            int m10 = 0;
            for(int j= -8;j&amp;lt;8;j++)
            {
                for(int i=-8;i&amp;lt;8;i++)
                {
                    m01 += j*image.at&amp;lt;uchar&amp;gt;(v+j,u+i);
                    m10 += i*image.at&amp;lt;uchar&amp;gt;(v+j,u+i); 
                }
            }
            kp.angle = (float)atan(m01/m10)*180/pi;
        }
        return;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.编写ORB描述子的代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    void computeORBDesc(const cv::Mat &amp;amp;image, vector&amp;lt;cv::KeyPoint&amp;gt; &amp;amp;keypoints, vector&amp;lt;DescType&amp;gt; &amp;amp;desc) 
    {
        for (auto &amp;amp;kp: keypoints) 
        {
            DescType d(256, false);
            for (int i = 0; i &amp;lt; 256; i++) 
            {
                int up = ORB_pattern[i*4];
                int vp = ORB_pattern[i*4+1];
                int uq = ORB_pattern[i*4+2];
                int vq = ORB_pattern[i*4+3];

                int up1 = up*cos(kp.angle/180*pi)-vp*sin(kp.angle/180*pi) + kp.pt.x;
                int vp1 = up*sin(kp.angle/180*pi)+vp*cos(kp.angle/180*pi) + kp.pt.y;

                int uq1 = uq*cos(kp.angle/180*pi)-vq*sin(kp.angle/180*pi) + kp.pt.x;
                int vq1 = uq*sin(kp.angle/180*pi)+vq*cos(kp.angle/180*pi) + kp.pt.y;

                if(up1&amp;lt;0 || up1&amp;gt;=image.cols || vp1&amp;lt;0 || vp1&amp;gt;=image.rows 
                || uq1&amp;lt;0 || uq1&amp;gt;=image.cols || vq1&amp;lt;0 || vq1&amp;gt;=image.rows)
                {
                    d.clear();
                    break;
                }
                else
                {
                    d[i] =( image.at&amp;lt;uchar&amp;gt;(vp1,up1)&amp;gt;image.at&amp;lt;uchar&amp;gt;(vq1,uq1) )?0:1;
                }
            }
            desc.push_back(d);  
        }

        int bad = 0;
        for (auto &amp;amp;d: desc) {
            if (d.empty()) bad++;
        }
        cout &amp;lt;&amp;lt; &amp;quot;bad/total: &amp;quot; &amp;lt;&amp;lt; bad &amp;lt;&amp;lt; &amp;quot;/&amp;quot; &amp;lt;&amp;lt; desc.size() &amp;lt;&amp;lt; endl;
        return;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.暴力匹配的代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    void bfMatch(const vector&amp;lt;DescType&amp;gt; &amp;amp;desc1, const vector&amp;lt;DescType&amp;gt; &amp;amp;desc2, vector&amp;lt;cv::DMatch&amp;gt; &amp;amp;matches) {
        int d_max = 50;
        int d1_num = -1;
        int time_stt = clock();
        for(auto &amp;amp;d1:desc1)
        {
            d1_num++;
            if(d1.empty())
            {
                continue;
            }
            //之所以使用二维数组，是因为不仅需要记录距离来排序，同时还要记录下标。
            vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; d1_match(0,vector&amp;lt;int&amp;gt;(2));
            int d2_num = -1;
        
            for(auto &amp;amp;d2:desc2)
            {
                d2_num++;
                if(d2.empty())
                {
                    continue;
                }
                int HammingDis = 0;//注意是d2每一次需要为0.
                vector&amp;lt;int&amp;gt; d2_hamming(2);
                for(int i = 0;i&amp;lt;256;i++)
                {
                    HammingDis += (d1[i] == d2[i])?0:1;
                }
                d2_hamming = {HammingDis, d2_num};
                d1_match.push_back(d2_hamming);
            }
            sort(d1_match.begin(), d1_match.end());
            if(d1_match[0][0]&amp;lt;d_max)
            {
                cv::DMatch m;
                m.queryIdx = d1_num;
                m.trainIdx = d1_match[0][1];
                m.distance = d1_match[0][0];
                matches.push_back(m);
            }
        }
        int time_end = clock();
        cout&amp;lt;&amp;lt;&amp;quot;time is &amp;quot;&amp;lt;&amp;lt;(time_end-time_stt)/(double)CLOCKS_PER_SEC&amp;lt;&amp;lt;&amp;quot;s&amp;quot;&amp;lt;&amp;lt;endl;
        for (auto &amp;amp;m: matches) {
            cout &amp;lt;&amp;lt; m.queryIdx &amp;lt;&amp;lt; &amp;quot;, &amp;quot; &amp;lt;&amp;lt; m.trainIdx &amp;lt;&amp;lt; &amp;quot;, &amp;quot; &amp;lt;&amp;lt; m.distance &amp;lt;&amp;lt; endl;
        }
        return;
    }

&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>非线性优化</title>
      <link>https://xlmaverick.me/post/%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://xlmaverick.me/post/%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96/</guid>
      
        <description>

&lt;h1 id=&#34;非线性优化&#34;&gt;非线性优化&lt;/h1&gt;

&lt;h2 id=&#34;习题一-矩阵微分&#34;&gt;习题一：矩阵微分&lt;/h2&gt;

&lt;p&gt;在优化中经常会遇到矩阵微分的问题。例如,当自变量为向量$x$,求标量函数$u(x)$对$x$的导数时,即为矩阵微分。通常线性代数教材不会深入探讨此事,这往往是矩阵论的内容。回答下列问题:
设变量为$x\in{R^N}$，那么:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;矩阵$A\in{R^{N×N}}$，那么$d(Ax)/dx$是什么？&lt;/li&gt;
&lt;li&gt;矩阵$A\in{R^{N×N}}$，那么$d(x^TAx)/dx$是什么？&lt;/li&gt;

&lt;li&gt;&lt;p&gt;证明：
&lt;p&gt;
$$
x^TA^Tx = tr(Axx^T ).
$$
&lt;/p&gt;&lt;/p&gt;

&lt;h4 id=&#34;分析&#34;&gt;分析&lt;/h4&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;涉及到矩阵和向量的求导，总共有五种类型，注意相关的顺序以及于雅各比矩阵的区别，再强调一次，雅各比矩阵的列数为自变量的个数，这一点要记清楚。
A.向量对标量；
B.标量对向量；
C.向量对向量；
D.矩阵对标量；
E.标量对矩阵；
他们分别对应的形式如下所示：&lt;br /&gt;
$$
向量对标量: \frac{\partial{Y}}{\partial{x}} = \begin{bmatrix} \frac{\partial{y_1}}{\partial{x}} \ \frac{\partial{y_2}}{\partial{x}} \  \vdots \ \frac{\partial{y_m}}{\partial{x}} \end{bmatrix}
$$&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;$$
 标量对向量: \frac{\partial{y}}{\partial{X}} = \begin{bmatrix} \frac{\partial{y}}{\partial{x_1}} &amp;amp; \frac{\partial{y}}{\partial{x_2}} &amp;amp;  \cdots &amp;amp; \frac{\partial{y}}{\partial{x_n}} \end{bmatrix}
$$&lt;/p&gt;

&lt;p&gt;$$
 向量对向量: \frac{\partial{Y}}{\partial{X}} = \begin{bmatrix} \frac{\partial{y_1}}{\partial{x_1}} &amp;amp; \frac{\partial{y_2}}{\partial{x_1}} &amp;amp;  \cdots &amp;amp; \frac{\partial{y_m}}{\partial{x_1}} \\
 \frac{\partial{y_1}}{\partial{x_2}} &amp;amp; \frac{\partial{y_2}}{\partial{x_2}} &amp;amp;  \cdots &amp;amp; \frac{\partial{y_m}}{\partial{x_2}} \\
 \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
  \frac{\partial{y_1}}{\partial{x_n}} &amp;amp; \frac{\partial{y_2}}{\partial{x_n}} &amp;amp;  \cdots &amp;amp; \frac{\partial{y_m}}{\partial{x_n}} \\
 \end{bmatrix}
$$&lt;/p&gt;

&lt;p&gt;
$$
 矩阵对标量: \frac{\partial{Y}}{\partial{x}} = \begin{bmatrix} \frac{\partial{y_{11}}}{\partial{x}} &amp; \frac{\partial{y_{21}}}{\partial{x}} &amp;  \cdots &amp; \frac{\partial{y_{m1}}}{\partial{x}} \\\\ 
 \frac{\partial{y_{12}}}{\partial{x}} &amp; \frac{\partial{y_{22}}}{\partial{x}} &amp;  \cdots &amp; \frac{\partial{y_{m2}}}{\partial{x}} \\\\ 
 \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\\\ 
  \frac{\partial{y_{1n}}}{\partial{x}} &amp; \frac{\partial{y_{2n}}}{\partial{x}} &amp;  \cdots &amp; \frac{\partial{y_{mn}}}{\partial{x}} \\\\ 
 \end{bmatrix}
$$
&lt;/p&gt;

&lt;p&gt;
$$
 标量对矩阵: \frac{\partial{y}}{\partial{X}} = \begin{bmatrix} \frac{\partial{y}}{\partial{x_{11}}} &amp; \frac{\partial{y}}{\partial{x_{12}}} &amp;  \cdots &amp; \frac{\partial{y}}{\partial{x_{1n}}} \\
 \frac{\partial{y}}{\partial{x_{21}}} &amp; \frac{\partial{y}}{\partial{x{22}}} &amp;  \cdots &amp; \frac{\partial{y}}{\partial{x_{2n}}} \\
 \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  \frac{\partial{y}}{\partial{x_{m1}}} &amp; \frac{\partial{y}}{\partial{x_{m2}}} &amp;  \cdots &amp; \frac{\partial{y}}{\partial{x_{mn}}} \\
 \end{bmatrix}
$$
&lt;/p&gt;

&lt;p&gt;我们常用的矩阵求导公式有：&lt;/p&gt;

&lt;p&gt;$$
    Y = A * X &amp;ndash;&amp;gt; \frac{\partial{Y}}{\partial{X}} = A^T
$$
$$
    Y = X * A &amp;ndash;&amp;gt; \frac{\partial{Y}}{\partial{X}} = A&lt;br /&gt;
$$
$$
    Y = A^T * X * B &amp;ndash;&amp;gt; \frac{\partial{Y}}{\partial{X}} = A * B^T&lt;br /&gt;
$$
$$
    Y = A^T * X^T * B &amp;ndash;&amp;gt; \frac{\partial{Y}}{\partial{X}} = B * A^T&lt;br /&gt;
$$
$$
    \frac{\partial{X^TX}}{\partial{X}} = X
$$&lt;/p&gt;

&lt;h4 id=&#34;答案&#34;&gt;答案：&lt;/h4&gt;

&lt;p&gt;1、设$Y=AX$，则$Y\in{R^{N*1}}$，所以$\frac{\partial{Y}}{\partial{X}}$属于向量对向量的形式，其中Y向量我们可以计算得出：&lt;/p&gt;

&lt;p&gt;
$$
Y = \begin{bmatrix} a_{11}*x_1+a_{12}*x_2+ \cdots + a_{1n}*x_n\\ 
a_{21}*x_1+a_{22}*x_2+ \cdots + a_{2n}*x_n \\  
\vdots \\ 
a_{n1}*x_1+a_{n2}*x_2+ \cdots + a_{nn}*x_n
\end{bmatrix}
$$
&lt;/p&gt;

&lt;p&gt;则我们由上述向量对向量的式子可以得到：&lt;/p&gt;

&lt;p&gt;
$$
\frac{\partial{Y}}{\partial{X}} = \begin{bmatrix} \frac{\partial{y_1}}{\partial{x_1}} &amp; \frac{\partial{y_2}}{\partial{x_1}} &amp;  \cdots &amp; \frac{\partial{y_m}}{\partial{x_1}} \\
 \frac{\partial{y_1}}{\partial{x_2}} &amp; \frac{\partial{y_2}}{\partial{x_2}} &amp;  \cdots &amp; \frac{\partial{y_m}}{\partial{x_2}} \\
 \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  \frac{\partial{y_1}}{\partial{x_n}} &amp; \frac{\partial{y_2}}{\partial{x_n}} &amp;  \cdots &amp; \frac{\partial{y_m}}{\partial{x_n}} \\
 \end{bmatrix}
 $$
 &lt;/p&gt;

&lt;p&gt;带入YX变量可得：&lt;/p&gt;

&lt;p&gt;&lt;p&gt;
 $$
    \frac{\partial{Y}}{\partial{X}} =
         \begin{pmatrix}
        a_ {11} &amp;amp; a_ {21}  &amp;amp; \cdots &amp;amp; a_ {n1} \\
        a_ {12} &amp;amp; a_ {22} &amp;amp; \cdots &amp;amp; a_ {n2}\\
        \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
        a_ {1n} &amp;amp; a_ {2n} &amp;amp; \cdots &amp;amp; a_ {nn} \\
        \end{pmatrix}
        = A^T
 $$
 &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;2、由第一问我们可以知道，$Y=AX$,我们设 $ Z = x^TY$，则我们可以知道$Z\in{R^{1*1}}$，则&lt;/p&gt;

&lt;p&gt;&lt;p&gt;
 $$
 Z = \sum_ {i=1}^n\sum_ {j=1}^n a_ {ij}*x_i*x_j
 $$
&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;则我们由上述标量对向量的式子可以得到：&lt;/p&gt;

&lt;p&gt;
 $$
 \frac{\partial{z}}{\partial{X}} = \begin{bmatrix} \frac{\partial{z}}{\partial{x_1}} &amp; \frac{\partial{z}}{\partial{x_2}} &amp;  \cdots &amp; \frac{\partial{z}}{\partial{x_n}} \end{bmatrix}
 $$
 &lt;/p&gt;

&lt;p&gt;我们计算出Z对与 $x_l$的导数为：&lt;/p&gt;

&lt;p&gt;
 $$
 \frac{\partial{z}}{\partial{x_l}} = \sum_{i=1}^nx_i*a_{il}+\sum_{j=1}^nx_j*a_{lj} = (A^T+A)x
 $$
 &lt;/p&gt;

&lt;p&gt;3、根据上述的第二问，我们可以将$x^TA^Tx$展开，同时可以将$Axx^T$展开，最终我们能够证明$x^TA^Tx = tr(Axx^T)$,这里不再展开叙述。&lt;/p&gt;

&lt;h2 id=&#34;习题二-高斯牛顿法的曲线拟合实验&#34;&gt;习题二：高斯牛顿法的曲线拟合实验&lt;/h2&gt;

&lt;p&gt;我们在课上演示了用&lt;code&gt;Ceres&lt;/code&gt;和&lt;code&gt;g2o&lt;/code&gt;进行曲线拟合的实验,可以看到优化框架给我们带来了诸多便利。本题中你需要自己实现一遍高斯牛顿的迭代过程,求解曲线的参数。我们将原题复述如下。设有曲线满足以下方程:&lt;/p&gt;

&lt;p&gt;
$$
y = exp(ax^2+bx+c)+w
$$
&lt;/p&gt;

&lt;p&gt;其中a,b,c为曲线参数,w为噪声。现有N个数据点(x,y)，希望通过此N个点来拟合a,b,c。实验中取$N = 100$。&lt;br /&gt;
那么，定义误差为 $ e_i = y_i-exp(ax_i^2+bx_i+c)$，于是$(a,b,c)$的最优解可通过解以下最小二乘获得：&lt;/p&gt;

&lt;p&gt;
$$
min_{a b c} = \frac{1}{2}\sum_{i=1}^N {||y_i - exp(ax_i^2+bx_i+c)||^2}
$$
&lt;/p&gt;

&lt;p&gt;现在请你书写 Gauss-Newton 的程序以解决此问题。&lt;/p&gt;

&lt;h4 id=&#34;分析-1&#34;&gt;分析&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;注意雅克比矩阵和矩阵微分的形式不同，雅克比矩阵列数为自变量的个数，例如本题中，雅克比矩阵的大小应为 $1*3$，雅克比矩阵和梯度矩阵的关系$A=J^T$。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;程序计算的时候，100个H矩阵相加，这一点可以考虑为100数据都这样的大矩阵，分模块相乘就是各个小模块相乘再累加的过程。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;一阶梯度法就是快速下降法，但是快速下降法过于贪心，容易出现锯齿路线，反而增加了迭代的次数。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;二阶梯度法就是牛顿法，缺点是需要计算H矩阵，在大规模的问题中这是很难实现的，我们一般避免计算H矩阵。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;一阶和二阶的方法，都是将$f(x)^2$在$x$附近泰勒展开，但是高斯牛顿的方法是将$f(x)$进行一阶泰勒展开。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;对于列文伯格-马夸尔特的方法，一般认为比高斯牛顿更为健壮，但是它收敛的速度可能会慢于高斯牛顿法，但却在SLAM中大量应用。&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;答案-1&#34;&gt;答案&lt;/h4&gt;

&lt;p&gt;程序最终结果如图所示：
&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/非线性优化/result.png&#34;&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;完整程序链接：&lt;a href=&#34;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/gauessnewton&#34;&gt;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/gauessnewton&lt;/a&gt;&lt;br /&gt;
代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    #include &amp;lt;iostream&amp;gt;
    #include &amp;lt;opencv2/opencv.hpp&amp;gt;
    #include &amp;lt;Eigen/Core&amp;gt;
    #include &amp;lt;Eigen/Dense&amp;gt;

    using namespace std;
    using namespace Eigen;

    int main(int argc, char **argv) 
    {
        double ar = 1.0, br = 2.0, cr = 1.0;         // 真实参数值
        double ae = 2.0, be = -1.0, ce = 5.0;        // 估计参数值
        int N = 100;                                 // 数据点
        double w_sigma = 1.0;                        // 噪声Sigma值
        cv::RNG rng;                                 // OpenCV随机数产生器

        vector&amp;lt;double&amp;gt; x_data, y_data;      // 数据
        for (int i = 0; i &amp;lt; N; i++) 
        {
            double x = i / 100.0;
            x_data.push_back(x);
            y_data.push_back(exp(ar * x * x + br * x + cr) + rng.gaussian(w_sigma));
        }

        // 开始Gauss-Newton迭代
        int iterations = 100;    // 迭代次数
        double cost = 0, lastCost = 0;  // 本次迭代的cost和上一次迭代的cost

        for (int iter = 0; iter &amp;lt; iterations; iter++) 
        {
            Matrix3d H = Matrix3d::Zero();             // Hessian = J^T J in Gauss-Newton
            Vector3d b = Vector3d::Zero();             // bias
            cost = 0;

            for (int i = 0; i &amp;lt; N; i++) 
            {
                double xi = x_data[i], yi = y_data[i];  // 第i个数据点
                double error = 0;   // 第i个数据点的计算误差
                error =yi -exp(ae*xi*xi+be*xi+ce); // 填写计算error的表达式
                Vector3d J; // 雅可比矩阵
                J[0] = -exp(ae*xi*xi+be*xi+ce)*xi*xi;  // de/da
                J[1] = -exp(ae*xi*xi+be*xi+ce)*xi;  // de/db
                J[2] = -exp(ae*xi*xi+be*xi+ce);  // de/dc

                H += J * J.transpose(); // GN近似的H
                b += -error * J;

                cost += error * error;
            }

            // 求解线性方程 Hx=b，建议用ldlt
            Vector3d dx;
            dx = H.ldlt().solve(b);

            if (isnan(dx[0])) 
            {
                cout &amp;lt;&amp;lt; &amp;quot;result is nan!&amp;quot; &amp;lt;&amp;lt; endl;
                break;
            }

            if (iter &amp;gt; 0 &amp;amp;&amp;amp; cost &amp;gt; lastCost) {
                // 误差增长了，说明近似的不够好
                cout &amp;lt;&amp;lt; &amp;quot;cost: &amp;quot; &amp;lt;&amp;lt; cost &amp;lt;&amp;lt; &amp;quot;, last cost: &amp;quot; &amp;lt;&amp;lt; lastCost &amp;lt;&amp;lt; endl;
                break;
            }

            // 更新abc估计值
            ae += dx[0];
            be += dx[1];
            ce += dx[2];

            lastCost = cost;

            cout &amp;lt;&amp;lt; &amp;quot;total cost: &amp;quot; &amp;lt;&amp;lt; cost &amp;lt;&amp;lt; endl;
        }

        cout &amp;lt;&amp;lt; &amp;quot;estimated abc = &amp;quot; &amp;lt;&amp;lt; ae &amp;lt;&amp;lt; &amp;quot;, &amp;quot; &amp;lt;&amp;lt; be &amp;lt;&amp;lt; &amp;quot;, &amp;quot; &amp;lt;&amp;lt; ce &amp;lt;&amp;lt; endl;
        return 0;
    }
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>相机与图像</title>
      <link>https://xlmaverick.me/post/%E7%9B%B8%E6%9C%BA%E4%B8%8E%E5%9B%BE%E5%83%8F/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://xlmaverick.me/post/%E7%9B%B8%E6%9C%BA%E4%B8%8E%E5%9B%BE%E5%83%8F/</guid>
      
        <description>

&lt;h1 id=&#34;相机与图像&#34;&gt;相机与图像&lt;/h1&gt;

&lt;h2 id=&#34;习题一-图像去畸变&#34;&gt;习题一：图像去畸变&lt;/h2&gt;

&lt;p&gt;现实生活中的图像总存在畸变。原则上来说,针孔透视相机应该将三维世界中的直线投影成直线,但是当我们使用广角和鱼眼镜头时,由于畸变的原因,直线在图像里看起来是扭曲的。本次作业,你将尝试如何对一张图像去畸变,得到畸变前的图像。&lt;/p&gt;

&lt;div style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;../images/相机与图像/test.png&#34; width = &#39;500&#39;&gt;
&lt;/div&gt;

&lt;p&gt;上图为本次练习的测试图片，来自EuRoC数据集。可以明显的看到实际的柱子、箱子的直线边缘在图像中被扭曲成了曲线。这就是由相机畸变造成的。根据我们在课上的介绍,畸变前后的坐标变换为:&lt;/p&gt;

&lt;p&gt;
$$
    \begin {cases}
    x_{distorted} = x(1+k_1r^2+k_2r^4)+2p_1xy+p_2(r^2+2x^2) \\
    y_{distorted} = y(1+k_1r^2+k_2r^4)+p_1(r^2+2y^2)+2p_2xy
    \end {cases}
$$
&lt;/p&gt;

&lt;p&gt;其中 $x,y$为去畸变后的坐标， $x_ {distorted},y_ {distroted}$为去畸变前的坐标。现给定参数:&lt;/p&gt;

&lt;p&gt;$$
    k_1 =−0.28340811,k_2=0.07395907,p_1 = 0.00019359,p_2 = 1.76187114e^{−05}
$$
以及相机内参&lt;/p&gt;

&lt;p&gt;$$
    f_x = 458.654, f_y = 457.296, c_x = 367.215, c_y = 248.375
$$
请根据&lt;code&gt;undistort_image.cpp&lt;/code&gt;文件中内容,完成对该图像的去畸变操作。&lt;/p&gt;

&lt;h4 id=&#34;答案&#34;&gt;答案：&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;视觉SALM十四讲中2017年第一版中关于畸变模型的公式是错误的，这一点以这次的为主。畸变公式表示从去畸变后的坐标到去畸变前的坐标变换。&lt;/li&gt;
&lt;li&gt;对其中$r$说明，为极坐标系下的距离，即$r^2=x^2+y^2$&lt;br /&gt;
最终程序的运行结果为：&lt;/li&gt;
&lt;/ol&gt;

&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/相机与图像/result.png&#34; width = &#39;500&#39;&gt;
&lt;/div&gt;

&lt;p&gt;完整程序链接：&lt;a href=&#34;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/undistort&#34;&gt;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/undistort&lt;/a&gt;&lt;br /&gt;
代码如下所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    #include &amp;lt;opencv2/opencv.hpp&amp;gt;
    #include &amp;lt;string&amp;gt;
    using namespace std;
    string image_file = &amp;quot;../../test.png&amp;quot;;   // 请确保路径正确
    int main(int argc, char **argv)
    {
        // 本程序需要你自己实现去畸变部分的代码。尽管我们可以调用OpenCV的去畸变，但自己实现一遍有助于理解。
        // 畸变参数
        double k1 = -0.28340811, k2 = 0.07395907, p1 = 0.00019359, p2 = 1.76187114e-05;
        // 内参
        double fx = 458.654, fy = 457.296, cx = 367.215, cy = 248.375;

        cv::Mat image = cv::imread(image_file,0);   // 图像是灰度图，CV_8UC1
        int rows = image.rows, cols = image.cols;
        cv::Mat image_undistort = cv::Mat(rows, cols, CV_8UC1);   // 去畸变以后的图

        // 计算去畸变后图像的内容
        for (int v = 0; v &amp;lt; rows; v++)
        {
            for (int u = 0; u &amp;lt; cols; u++) 
            {
                
                double u_distorted = 0, v_distorted = 0;
                // TODO 按照公式，计算点(u,v)对应到畸变图像中的坐标(u_distorted, v_distorted) (~6 lines)
                // start your code here
                double x = (u-cx)/fx;
                double y = (v-cy)/fy;

                double r2 = x*x+y*y;
                double r4 = r2*r2;

                double x_distorted = x*(1+k1*r2+k2*r4)+2*p1*x*y+p2*(r2+2*x*x);
                double y_distorted = y*(1+k1*r2+k2*r4)+p1*(r2+2*y*y)+2*p2*x*y;

                u_distorted = fx*x_distorted+cx;
                v_distorted = fy*y_distorted+cy;

                // end your code here

                // 赋值 (最近邻插值)
                if (u_distorted &amp;gt;= 0 &amp;amp;&amp;amp; v_distorted &amp;gt;= 0 &amp;amp;&amp;amp; u_distorted &amp;lt; cols &amp;amp;&amp;amp; v_distorted &amp;lt; rows) 
                {
                    image_undistort.at&amp;lt;uchar&amp;gt;(v, u) = image.at&amp;lt;uchar&amp;gt;((int) v_distorted, (int) u_distorted);
                }
                else 
                {
                    image_undistort.at&amp;lt;uchar&amp;gt;(v, u) = 0;
                }
            }
        }
        // 画图去畸变后图像
        cv::imwrite(&amp;quot;../../result.png&amp;quot;, image_undistort);
        cv::imshow(&amp;quot;image undistorted&amp;quot;, image_undistort);
        cv::waitKey();
        return 0;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;习题二-双目视差的使用&#34;&gt;习题二：双目视差的使用&lt;/h2&gt;

&lt;p&gt;双目相机的一大好处是可以通过左右目的视差来恢复深度。课程中我们介绍了由视差计算深度的过程。本题,你需要根据视差计算深度,进而生成点云数据。本题的数据来自 Kitti 数据集。&lt;br /&gt;
Kitti 中的相机部分使用了一个双目模型。双目采集到左图和右图,然后我们可以通过左右视图恢复出深度。经典双目恢复深度的算法有 BM(Block Matching),SGBM(Semi-Global Matching)等,但本题不探讨立体视觉内容(那是一个大问题)。我们假设双目计算的视差已经给定,请你根据双目模型,画出图像对应的点云,并显示到 Pangolin 中。&lt;br /&gt;
本题给定左右图、视差图。双目的参数如下:
$$
    f_x = 718.856, f_y = 718.856, c_x = 607.1928, c_y = 185.2157
$$
且双目左右间距(即基线)为:
$$
    d = 0.573 m
$$
请根据以上的参数，计算相机数据对应的点云，并显示到Pangolin中。&lt;/p&gt;

&lt;h4 id=&#34;答案-1&#34;&gt;答案：&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;注意代码中&lt;code&gt;vector&amp;lt;Vector4d, Eigen::aligned_allocator&amp;lt;Vector4d&amp;gt;&amp;gt; pointcloud&lt;/code&gt;，其中&lt;code&gt;Eigen::aligned_allocator&amp;lt;Vector4d&amp;gt;&lt;/code&gt;是描述&lt;code&gt;vector&lt;/code&gt;中的&lt;code&gt;Allocator type&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;相机模型中使用的是坐标，而相应坐标里面的数值并没有考虑。&lt;/li&gt;
&lt;li&gt;相机的模型中我们共用到四种坐标：世界坐标、相机坐标、归一化相机坐标和像素坐标。其中畸变模型是在归一化相机坐标上讨论的。对于具体的问题，需要考虑合适的正确的坐标对应关系。&lt;/li&gt;
&lt;li&gt;视差图转为深度图信息,公式当中的量纲,双目图片两侧小部分没有视差信息。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最终程序运行的结果（结果中是一个三维的图，前后重叠在一起了）：&lt;br /&gt;
左右图如下所示：&lt;br /&gt;
&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/相机与图像/left.png&#34;  width=&#34;350&#34;/&gt;&lt;img src=&#34;../images/相机与图像/right.png&#34;  width=&#34;350&#34;/&gt;
&lt;/div&gt;
视差图如下所示：&lt;br /&gt;
&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/相机与图像/disparity.png&#34; width=&#34;500&#34;/&gt;
&lt;/div&gt;
最终生成的点云图如下所示：
&lt;div style=&#34;text-align:center&#34;&gt;
&lt;img src=&#34;../images/相机与图像/result1.png&#34; width=&#34;500&#34;/&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;完整程序链接：&lt;a href=&#34;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/disparity&#34;&gt;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/vslam_fourteen_lectures/disparity&lt;/a&gt;&lt;br /&gt;
代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    #include &amp;lt;opencv2/opencv.hpp&amp;gt;
    #include &amp;lt;string&amp;gt;
    #include &amp;lt;Eigen/Core&amp;gt;
    #include &amp;lt;pangolin/pangolin.h&amp;gt;
    #include &amp;lt;unistd.h&amp;gt;

    using namespace std;
    using namespace Eigen;

    // 文件路径，如果不对，请调整
    string left_file = &amp;quot;../../left.png&amp;quot;;
    string right_file = &amp;quot;../../right.png&amp;quot;;
    string disparity_file = &amp;quot;../../disparity.png&amp;quot;;

    // 在panglin中画图，已写好，无需调整
    void showPointCloud(const vector&amp;lt;Vector4d, Eigen::aligned_allocator&amp;lt;Vector4d&amp;gt;&amp;gt; &amp;amp;pointcloud);

    int main(int argc, char **argv) {

        // 内参
        double fx = 718.856, fy = 718.856, cx = 607.1928, cy = 185.2157;
        // 间距
        double b = 0.573;

        // 读取图像
        cv::Mat left = cv::imread(left_file, 0);
        cv::Mat right = cv::imread(right_file, 0);
        cv::Mat disparity = cv::imread(disparity_file, 0); // disparty 为CV_8U,单位为像素

        // 生成点云
        vector&amp;lt;Vector4d, Eigen::aligned_allocator&amp;lt;Vector4d&amp;gt;&amp;gt; pointcloud;

        // TODO 根据双目模型计算点云
        // 如果你的机器慢，请把后面的v++和u++改成v+=2, u+=2
        for (int v = 0; v &amp;lt; left.rows; v++)
            for (int u = 0; u &amp;lt; left.cols; u++) {

                Vector4d point(0, 0, 0, left.at&amp;lt;uchar&amp;gt;(v, u) / 255.0); // 前三维为xyz,第四维为颜色

                // start your code here (~6 lines)
                // 根据双目模型计算 point 的位置
                uchar  d= disparity.at&amp;lt;uchar&amp;gt;(v,u);
                point[2] = (fx*b)/d;
                point[1] = point[2]*(v-cy)/fy;
                point[0] = point[2]*(u-cx)/fx;
                pointcloud.push_back(point);
                // end your code here
            }
        cout&amp;lt;&amp;lt;&amp;quot;pointcloud size: &amp;quot;&amp;lt;&amp;lt;pointcloud.size()&amp;lt;&amp;lt;endl;
        // 画出点云
        showPointCloud(pointcloud);
        return 0;
    }

    void showPointCloud(const vector&amp;lt;Vector4d, Eigen::aligned_allocator&amp;lt;Vector4d&amp;gt;&amp;gt; &amp;amp;pointcloud) {

        if (pointcloud.empty()) {
            cerr &amp;lt;&amp;lt; &amp;quot;Point cloud is empty!&amp;quot; &amp;lt;&amp;lt; endl;
            return;
        }

        pangolin::CreateWindowAndBind(&amp;quot;Point Cloud Viewer&amp;quot;, 1024, 768);
        glEnable(GL_DEPTH_TEST);
        glEnable(GL_BLEND);
        glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA);

        pangolin::OpenGlRenderState s_cam(
                pangolin::ProjectionMatrix(1024, 768, 500, 500, 512, 389, 0.1, 1000),
                pangolin::ModelViewLookAt(0, -0.1, -1.8, 0, 0, 0, 0.0, -1.0, 0.0)
        );

        pangolin::View &amp;amp;d_cam = pangolin::CreateDisplay()
                .SetBounds(0.0, 1.0, pangolin::Attach::Pix(175), 1.0, -1024.0f / 768.0f)
                .SetHandler(new pangolin::Handler3D(s_cam));

        while (pangolin::ShouldQuit() == false) {
            glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

            d_cam.Activate(s_cam);
            glClearColor(1.0f, 1.0f, 1.0f, 1.0f);

            glPointSize(2);
            glBegin(GL_POINTS);
            for (auto &amp;amp;p: pointcloud) {
                glColor3f(p[3], p[3], p[3]);
                glVertex3d(p[0], p[1], p[2]);
            }
            glEnd();
            pangolin::FinishFrame();
            usleep(5000);   // sleep 5 ms
        }
        return;
    }
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>终食之言--电影春节档</title>
      <link>https://xlmaverick.me/post/%E7%BB%88%E9%A3%9F%E4%B9%8B%E8%A8%80--%E7%94%B5%E5%BD%B1%E6%98%A5%E8%8A%82%E6%A1%A3/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://xlmaverick.me/post/%E7%BB%88%E9%A3%9F%E4%B9%8B%E8%A8%80--%E7%94%B5%E5%BD%B1%E6%98%A5%E8%8A%82%E6%A1%A3/</guid>
      
        <description>&lt;p&gt;过年总得有消遣，一群人尬聊，找话题也是件头疼的事，所以啊，有些人一起吃饭，有些人打麻将，诚然，打麻将得需要加赌注，吃饭需要喝酒，总有一个办法调动气氛，打开人的话匣子。后来，感谢党，感谢国家，感谢那一路飙升的GDP，在满足人们日益增长的物质需求的同时，最终没有忘记人们日益增长的文化需求，当然，最终还得靠资本驱动，这几年电影行业的蒸蒸日上，有人名利双收的同时，人们也终于找到了一个不用尬聊，时间也很长，而且参与人员众多的活动，看电影，合大欢喜。&lt;br /&gt;
短短的这几天，流浪地球、疯狂的外星人、飞驰人生，总之大家觉得优秀的片子都随着朋友看着差不多。疯狂外星人中规中矩吧，期待和收获大家都懂。流浪地球，只有一个瑕点，比较讨厌刘启和韩朵朵，每次看到他总想冲上去打他一顿的错觉，难道是年纪大了？总感觉他就是那衬衫上的白米粒,墙上的一抹蚊子血。唉，还是很期待有一天能看到三体也能搬上大屏幕，或者像鬼吹灯一样，做成优质的网剧。最出人意料的还是飞驰人生吧，韩寒还是那一个勇敢无畏的韩寒，我们这一代人，看着他的书，听着他故事的普通人，在这个不三不四的年纪，人五人六的活着，却做着杂七杂八的琐事，很多人谈不上热爱，也谈不上厌恶，却总有一个理由维持着这种状态，还有一些人至今也没找到自己热爱什么啊。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>C&#43;&#43;基础知识--变量和基本类型2</title>
      <link>https://xlmaverick.me/post/c&#43;&#43;%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86--%E5%8F%98%E9%87%8F%E5%92%8C%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B2/</link>
      <pubDate>Wed, 26 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://xlmaverick.me/post/c&#43;&#43;%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86--%E5%8F%98%E9%87%8F%E5%92%8C%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B2/</guid>
      
        <description>

&lt;h2 id=&#34;string-vector-array&#34;&gt;string vector array&lt;/h2&gt;

&lt;h3 id=&#34;string&#34;&gt;string&lt;/h3&gt;

&lt;p&gt;1、using的声明最好不要放到头文件中，因为很多地方包含头文件，容易造成命名空间冲突。&lt;br /&gt;
2、string对象会自动忽略开头处的空白，从第一个字符读起，直到遇到下一处的空白结束。&lt;br /&gt;
3、string中getline()函数除外，如果开头有换行符，则直接返回，不会忽略开头处的空白。&lt;br /&gt;
4、string标准库中的size函数，返回的为string::size_type类型的值，该类型的值为无符号的类型，所以使用尤其注意和有符号的变量运算时，有符号的变量会变为无符号的数据，在for和if中很容易出错。&lt;br /&gt;
5、string对象相加，必须确保+号的两端至少有一个string，直接的字符串是不能够直接相加的。&lt;br /&gt;
6、范围for语句：&lt;br /&gt;
&lt;code&gt;string s;
for（auto c: s)&lt;/code&gt;&lt;br /&gt;
使用范围for可以方便遍历string 和vector，同时可以避免string的下标超过范围。&lt;br /&gt;
7、无论什么时候使用下标，一定要检查其合法性：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A：下标的类型，可以使用decltype和auto；
B：下标是否超过范围；
C：下标是否可以使用；（空的vector和string尤其注意）  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;8、string是c++的标准库，就想定义了大家共同使用的类，所以有一些大家都可以方便使用的类中的方法，举一个例子：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;string s(&amp;quot;some string&amp;quot;);  
for (decltype(s.size()) index=0; index != s.size() &amp;amp;&amp;amp; !isspace(s[index]); ++index)  
{  
    s[index] = toupper(s[index]); 
}  
cout&amp;lt;&amp;lt;s&amp;lt;&amp;lt;endl;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个例子主要说明C++中封装的思想和编码的风格。&lt;/p&gt;

&lt;h3 id=&#34;vector&#34;&gt;vector&lt;/h3&gt;

&lt;p&gt;1、vector是模板不是类型，所以vector容纳的为对象，引用不是对象，所以不存在包含引用的vector。&lt;br /&gt;
2、vector列表初始化时，主要看花括号和圆括号，以及类型：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vector&amp;lt;int&amp;gt; v1(10)
vector&amp;lt;int&amp;gt; v2{10}
vector&amp;lt;int&amp;gt; v3(10,1)
vector&amp;lt;int&amp;gt; v4{10,1}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意区分上述表达式的不同；&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vector(string) s1{&amp;quot;hi&amp;quot;}
vector(string) s2(&amp;quot;hi&amp;quot;)//错误
vector(string) s3{10} 
vector(string) s4{10,&amp;quot;hi&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3、向vector中添加元素，一般是定义一个空的vector，然后使用push_bsck函数进行添加，这时候是不能使用下标进行赋值的，因为此时是空的vector，不存在下标，添加元素后，可以使用下标进行访问。这种情况经常使用在未知数据数量的时候经常使用。&lt;br /&gt;
4、向vector中添加元素，必须要确保所写的循环正确无误，尤其是循环可能要改变vector对象容量的时候。（如果循环体内部包含向vector对象添加元素的语句，则不能使用范围for循环，因为范围for循环会预知end的位置）。&lt;br /&gt;
5、string和vector大小的比较，均遵循两个原则：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A：两个对象的容量不同，但相同位置的元素均相同，则容量大的对象大；  
B：两个对象的元素值不同，则第一对不同的元素值决定大小关系。  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6、string和vector有一个区别就是cout打印的区别，string可以直接的使用cout打印出所有的，但是vector是不可以是直接使用cout的，需要使用for或者范围for来cout打印出每一个元素（注意下标问题）。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>C&#43;&#43;基础知识--变量和基本类型1</title>
      <link>https://xlmaverick.me/post/c&#43;&#43;%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86--%E5%8F%98%E9%87%8F%E5%92%8C%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B1/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://xlmaverick.me/post/c&#43;&#43;%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86--%E5%8F%98%E9%87%8F%E5%92%8C%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B1/</guid>
      
        <description>

&lt;h3 id=&#34;变量和基本类型&#34;&gt;变量和基本类型&lt;/h3&gt;

&lt;p&gt;1、执行浮点运算选用double，以为float通常精度不够而且双精度浮点数和单精度浮点数的计算代价相差无几，甚至某些机器上，双精度运算甚至比单精度的快。&lt;br /&gt;
2、当我们赋值无符号类型超过范围时，其结果为该类型表示数值的总数取模后的余数，例如&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;unsigned char a = -4 ;     //a的值为-4+256=252   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3、当我们赋值有符号类型超过范围时，其结果是无意义的，此时程序可能继续工作，也可能会崩溃，也有可能产生垃圾数据，例如&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;signed char a = 256 //此时a是无定义的
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4、表达式中既有无符号的数字，又有带符号的数字是，会强制转换为无符号的数字。&lt;br /&gt;
5、减法运算带有强制的类型转换，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;unsigned char a = 40, b =10;
std::cout&amp;lt;&amp;lt;b-a&amp;lt;&amp;lt;endl;      //此时输出的结果为-30
signed char a = 40, b =10;
std::cout&amp;lt;&amp;lt;b-a&amp;lt;&amp;lt;endl;    //此时输出的结果为-30
unsigned int a = 40, b =10;
std::cout&amp;lt;&amp;lt;b-a&amp;lt;&amp;lt;endl;    //此时输出的结果为4294967266
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是因为减法运算会将unsigned char 或者signed char转换为int类型后进行减法操作，但是unsigned int不会进行强制转换，这一点很容易出错。&lt;br /&gt;
6、字符和字符串的区别，字符串包含结束符\0，同时是单引号和双引号的区别。&lt;br /&gt;
7、C++中初始化和赋值是两个完全不同的操作，初始化的含义是创建变量的时候赋予其一个初始值，复制的含义是把对象当前的值擦除，用一个新值替代。&lt;br /&gt;
8、变量初始化的方式有四种：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; int temp = 0； 
 int temp = {0}；
 int temp = {0}；
 int temp = （0）；
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中第二种、第三种称作列表初始化，列表初始化时不能进行类型转换。&lt;br /&gt;
9、使用未初始化的变量可能会带来无法预计的后果，建议初始化每一个内置类型的变量。&lt;br /&gt;
10、extern关键字表示声明的含义，extern语句包含初始化值的情况下将不是声明，而是定义。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;extern int i； //声明i而非定义
int i； //定义
extern int i = 2； //定义
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;变量只能定义一次，但是可以声明多次，尤其是分块编程的时候。&lt;br /&gt;
11、c++变量命名规范：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;标识要能体现实际含义；
变量名一般用小写，例如index，不要使用Index或者INDEX；  
用户自定义的的类名一般以大写字母开头，例如Sale_item；  
如果标识由多个单词组成，则单词应有明显的区分，如student_loan studentLoan；  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后，命名规范这件事，若能坚持，必将有效。&lt;br /&gt;
12、在对象第一次使用的地方附近定义它是一种较好的选择，这样有助于找到变量的定义，而且有助于赋给一个合适的初值。&lt;br /&gt;
13、如果函数有可能用到一个全局的变量，则最好不要再定义一个同名的局部变量。（是针对同一个名字在不同的作用域可能指向不同的实体的情况）&lt;br /&gt;
14、引用：引用为对象起另一个名字，引用必须初始化，初始值也必须为一个对象，同时类型应保持一致，而且引用本身不是一个对象，不能定义引用的引用。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int ival = 1024;
int &amp;amp;reival = ival;// 正确 引用
int &amp;amp;reval2;// 错误，引用必须初始化
double temp = 3.14；
int &amp;amp;retemp = temp；//错误，引用的类型必须保持一致
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;15、指针：指针本身就是一个对象，允许对指针进行赋值和拷贝，而且在指针的生命周期内能先后指向不同的对像。指针无需在定义的时候赋初值，如果指针没有被初始化，将拥有一个不确定的值。但是，使用未经初始化的指针是引发问题的重要原因，建议初始化所有的指针，并且在可能的情况下，尽量定义了对象之后在定义指向他的指针。如果实在不能确定指针指向何处，初始化为nullptr和0，然后在程序中每次使用指针前先进性判断，尽可能的减少错误的可能。&lt;br /&gt;
16、空指针的定义：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int  *p1 = nullptr;//
int  *p2 = 0;//
int  *p3 = NULL;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但是把int变量直接赋给指针是错误的操作，即使这个int变量的值等于0；&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int zero = 0；
p1 = zero；//错误，不能讲int类型的变量直接赋给指针
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;17、因为引用不是一个实际的对象，故不能定义指向引用的指针；&lt;br /&gt;
18、指针的类型和它所指向的对象的类型需要严格的匹配；&lt;br /&gt;
19、指针定义的时候，和具体使用指针的时候有下面的区别：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int  pd =42; 
int  *p1 = pd; int *p1 =  &amp;amp;pd;//这两种定义的方式都正确 第一种 初始值是指向int对象的指针；第二种是初始值是int型对象的地址。
定义完之后，p1表示地址，*p1表示指向的对象，即pd；
*p1 = &amp;amp;pd//错误
为*p赋值实际是为p1所指向的对象复制，所以*解引用操作只适用于那些明确指向了对象的指针。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;20 、int*  p1 和 int   &lt;em&gt;p1 的作用是一样的，而且int&lt;/em&gt; 没有批量操作的作用，所以这两种写法只要坚持其中的一种即可，在接下来的博客中，均采用第二种方法。&lt;br /&gt;
21、距离变量名最近的符号对变量的类型有最直接的影响：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int p = 42;
int *p1 = &amp;amp;p;
int  **p2 =  &amp;amp;p1;//指向指针的指针
int  *&amp;amp;p3 = p1;//对一个指针的引用
p3 = &amp;amp;p;//p3引用了一个指针，因此可以将地址赋给p3
*p3 = 0; //将p3引用的指针解引用操作，再复制，就是p目前为0。
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>视觉作业-1</title>
      <link>https://xlmaverick.me/post/%E8%A7%86%E8%A7%89%E4%BD%9C%E4%B8%9A-1/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://xlmaverick.me/post/%E8%A7%86%E8%A7%89%E4%BD%9C%E4%B8%9A-1/</guid>
      
        <description>

&lt;h3 id=&#34;背景&#34;&gt;背景&lt;/h3&gt;

&lt;p&gt;本学期，由于邹老师开设视觉定位的课程，我们组的大部分人基本每节课都在听，本次课程邹老师总共会设置六次大作业，应该难度不会很大。既然来上课了，所以就把相关的作业也做了。具体的代码和课件，我会放到自己的github上面：&lt;a href=&#34;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/homework_PPT_Zou_2018/Partial_code&#34;&gt;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/homework_PPT_Zou_2018/Partial_code&lt;/a&gt; ；&lt;br /&gt;
第一次作业是Histogram Specialization，是图像处理中基本的操作了，要求是不能使用相关的函数库，具体的要求和代码如下所示：&lt;/p&gt;

&lt;h3 id=&#34;作业要求&#34;&gt;作业要求&lt;/h3&gt;

&lt;p&gt;Write a small program to implement a histogram specialization algorithm.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Consider two brightness mapping functions transform both histograms into a constant histogram:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;../images/视觉作业-1/Histogram-1.png&#34; alt=&#34;&#34; /&gt;{:height=&amp;ldquo;50%&amp;rdquo; width=&amp;ldquo;50%&amp;rdquo;}&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Algorithm:&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;../images/视觉作业-1/Histogram-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;代码说明&#34;&gt;代码说明&lt;/h3&gt;

&lt;p&gt;工程共实现了三种功能，直方图均衡化、直方图特例化和显示直方图。分别对应的函数为：&lt;br /&gt;
cv::Mat histogram_specilalization(cv::Mat srcImage, cv::Mat dstImage)；&lt;br /&gt;
cv::Mat histogram_equalization(cv::Mat srcImage)；&lt;br /&gt;
void histogram_show(cv::Mat srcImage)。&lt;/p&gt;

&lt;p&gt;具体的实现思路如上述的算法所示。&lt;br /&gt;
代码运行方法为：
cd build&lt;br /&gt;
cmake ..&lt;br /&gt;
make&lt;br /&gt;
./Histogram_specialization&lt;/p&gt;

&lt;p&gt;完整程序链接：&lt;a href=&#34;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/homework_PPT_Zou_2018/Partial_code&#34;&gt;https://github.com/XLMaverick/Visual-Localization-Percessing/tree/master/homework_PPT_Zou_2018/Partial_code&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>相机模型与标定</title>
      <link>https://xlmaverick.me/post/%E7%9B%B8%E6%9C%BA%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%A0%87%E5%AE%9A/</link>
      <pubDate>Mon, 01 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://xlmaverick.me/post/%E7%9B%B8%E6%9C%BA%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%A0%87%E5%AE%9A/</guid>
      
        <description>

&lt;p&gt;由于近期使用了很多种不同的相机，关于相机的模型和标定方法也是老生常谈的问题，这也是视觉定位的必要前提，本文只要分为三个部分：坐标系的转换、相机模型和畸变模型。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;坐标系转换&lt;br /&gt;
像素坐标、图像坐标、摄像机坐标、世界坐标，其中世界坐标到摄像机坐标为刚体变换、摄像机坐标到图像坐标为透视投影、图像坐标到像素坐标为二次转换，牵扯到的具体的相机的内参矩阵和外参矩阵。&lt;/li&gt;
&lt;li&gt;相机的模型&lt;br /&gt;
相机模型分为针孔模型（线性模型）和非线性模型（鱼眼相机）&lt;/li&gt;
&lt;li&gt;畸变模型&lt;br /&gt;
畸变一般可以分为：径向畸变、切向畸变径向畸变来自于透镜形状。切向畸变来自于整个摄像机的组装过程。对于鱼眼相机，存在比较严重的畸变，主要是径向形变（普通相机也有，也会有轻微的切向形变）。针对具体的标定时，常用的畸变模型有fisheye模型、多项式畸变模型、ATAN模型和FOV模型。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;具体的标定工具：&lt;br /&gt;
* Matlab 标定工具箱&lt;br /&gt;
* Ros标定工具&lt;br /&gt;
* opencv标定工具&lt;br /&gt;
* 在github中，邹丹平老师有一套标定代码，我们通常用来标定鱼眼相机，该工具中已有的畸变模型有FOV模型，fisheye模型和Plumb—Bob模型。&lt;br /&gt;
* 对于SVO算法，由于ATAN标定的模型参数便于快速计算，故常采用PTAM中的标定程序来标定ATAN畸变模型。&lt;br /&gt;
上述只是本人常常使用的方法，欢迎大家推荐和指正。&lt;/p&gt;

&lt;h3 id=&#34;总结-2018-10-02&#34;&gt;总结 2018-10-02&lt;/h3&gt;

&lt;p&gt;本次主要是缕清相机模型、畸变模型还有常用的坐标转换之间的关系，同一种相机可以使用不同的畸变模型进行标定。比如，同一种鱼眼相机，可以采用FOV畸变模型进行来标定，同样可以采用ATAN畸变模型进行标定，标定的结果的具体含义是不同的。对于具体的数学关系的推算，以及相应的标定工具的具体使用方法，接下来会详细说明，其中是以邹老师的标定程序为主体框架，详细的介绍标定的代码流程和使用方法，同时也会相应的介绍不同的畸变模型下对应的解畸变方法，具体的代码也会公布到github主页上面。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>github的问题</title>
      <link>https://xlmaverick.me/post/github%E7%9A%84%E9%97%AE%E9%A2%98/</link>
      <pubDate>Thu, 13 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://xlmaverick.me/post/github%E7%9A%84%E9%97%AE%E9%A2%98/</guid>
      
        <description>&lt;ul&gt;
&lt;li&gt;&lt;p&gt;git 提交github后文件夹为灰颜色问题&lt;br /&gt;
因为使用git clone 之后，文件夹里面会包含原来相关的信息，所以重新push之后会显示灰颜色。解决方案：&lt;br /&gt;
* 删除clone的代码里面的.git和.gitignore文件，重新push。&lt;br /&gt;
* 若上述方法无效时，是因为已经有了缓存，需要先将缓存删除&lt;br /&gt;
git rm -r &amp;ndash;cached some-directory&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;git提交空文件夹&lt;br /&gt;
在空目录下创建.gitkeep文件。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;push 每次需要输入用户名和密码的问题&lt;br /&gt;
每次都需要输入用户名和密码是因为你采用的是 https 方式提交代码， 如果采用的是 ssh 方式只需要在版本库中添加用户的 sha 的key就可以实现提交时无需输入用户名和密码。&lt;br /&gt;
可以在更改配置HTTPS地址为SSH地址，当然也可以通过设置git的cache，可以让它记住密码，之后自己设置一个cache有效时间 这样也一定程度保证了一些安全性，具体代码如下&lt;br /&gt;
git config &amp;ndash;global credential.helper cache&lt;br /&gt;
git config &amp;ndash;global credential.helper &amp;lsquo;cache &amp;ndash;timeout=3600&amp;rsquo;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>写在博客边上</title>
      <link>https://xlmaverick.me/post/%E5%86%99%E5%9C%A8%E5%8D%9A%E5%AE%A2%E8%BE%B9%E4%B8%8A/</link>
      <pubDate>Wed, 12 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://xlmaverick.me/post/%E5%86%99%E5%9C%A8%E5%8D%9A%E5%AE%A2%E8%BE%B9%E4%B8%8A/</guid>
      
        <description>&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;关于这个博客的起因是随机的，关于这个博客的过程是曲折的，关于这个博客的结果，只能是看缘分了。前前后后，断断续续，中间因为比赛的原因暂停、因为论文的原因暂停，幸得朱一帆同学的再三帮忙，终究是还是建立完善起来了，由于一些特殊的原因，很多的经历未曾完善，姑且这样吧。&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;凡事贵在一悟，一悟又在久修之后。起初的想法在于记录调试旋翼无人机的点点滴滴，旋翼无人机从机械结构、硬件平台到软件算法，涵盖各个领域，从头搭建一架稳定可控的旋翼无人机，是一件磨人心智的工作，需要一点一滴、反复尝试。想到自己当初是一直渴望有一个成功过的手册指导自己，所以想通过这个开源的博客，把自己踩过的坑、掉过的洞分享记录起来，再方便自己总结和反思的同时，希望能帮助更多的人。第二点在于，研究总是曲折前进的，对一个问题反复思考之后，会有自己的认知，随着时间的推进，可能还会有新的想法，温故而知新，记录过程，反复的推敲，总归不是坏事。&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;偶然一啸当空发，孤鸿万里应声泣。经历了一件事后，总归有所感触感悟，当时刻骨铭心，后来不过如此，再细细回味，可能再也不会有当时感觉，甚至在记忆中消失殆尽，岁月长，衣裳薄。开设这个博客，记录的同时，也希望自己不要被一时的感慨感触感悟搞迷糊，凡心所向，素履所往，希望自己不要徒碌碌滞于俗，默默束于情。&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;今天就这样吧，明天还要开组会，以后慢慢补充吧。&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>